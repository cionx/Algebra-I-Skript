\chapter{Semisimple Modules and Rings}


In this chapter we will require all modules over unitary rings to be unitary, i.e.\ if $R$ is a ring with $1$ and $M$ an $R$-module then
\[
    1 \cdot m
  = m
  \text{ for all }
  m \in M \,.
\]
We also require all $k$-algebras to be unitary.
In particular modules over $k$-algebras are always $k$-vector spaces and module-homomorphisms are always $k$-linear.





\section{Semisimple Modules}


\begin{proposition}\label{proposition: characterisation semisimple modules}
  Let $R$ be a ring and $M$ an $R$-module. Then the following are equivalent:
  \begin{enumerate}[label=\emph{\roman*)},leftmargin=*]
    \item \label{enum: sum of simple}
      $M$ is the sum ob simple submodules.
    \item \label{enum: direct sum of simple}
      $M$ is the direct sum of simple submodules. 
    \item \label{enum: direct complements}
      Every submodule of $M$ has a direct complement.
  \end{enumerate}
\end{proposition}


\begin{definition}
  Let $R$ be a ring and $M$ an $R$-module.
  $M$ is called \emph{semisimple (over $R$)} if it satisfies one (and thus all) of the above conditions.
\end{definition}


\begin{proof}
  \ref{enum: sum of simple} $\implies$ \ref{enum: direct complements}:
  Suppose that $M = \sum_{i \in I} L_i$ where $L_i \subseteq M$ is a simple submodule for all $i \in I$ and let $U \subseteq M$ be a submodule.
  For all $J \subseteq I$ let
  \[
              M_J
    \coloneqq \sum_{j \in J} L_j \,.
  \]
  Using Zorn’s Lemma let $J_0 \subseteq I$ be maximal with \mbox{$U \cap M_{J_0} = 0$}.
  We claim that $M = U \oplus M_{J_0}$.
  
  Suppose this is not the case.
  Then there exists some $i_0 \in I$ such that
  \[
                L_{i_0}
    \nsubseteq  U \oplus M_{J_0}
  \]
  In particular $i_0 \notin J_0$.
  Since $L_{i_0}$ is simple we find that
  \[
      L_{i_0} \cap (U \oplus M_{J_0})
    = 0 \,.
  \]
  Therefore the sum
  \[
    L_{i_0} + (U \oplus M_{J_0})
  \]
  is direct. Since
  \[
      L_{i_0} \oplus (U \oplus M_{J_0})
    = U \oplus (L_{i_0} \oplus M_{J_0})
  \]
  we find for $J_1 \coloneqq J_0 \cup \{i_0\} \supsetneq J_0$
  \[
      U \cap M_{J_1}
    = 0 \,.
  \]
  This contradicts the maximality of $J_0$.
  
  \ref{enum: direct complements} $\implies$ \ref{enum: direct sum of simple}:
  We first notice the following:
  
  \begin{claim}
    If $U \subseteq N \subseteq M$ are submodules then $U$ has a direct complement in $N$.
  \end{claim}
  \begin{proof}
    Let $V \subseteq M$ be a direct complement of $U$ in $M$, i.e.\ $M = U \oplus V$.
    Then
    \[
      N = U \oplus (V \cap N) \,.
    \]
    To see this fix $n \in N$.
    Let $u \in U$ and $v \in V$ with $n = u + v$.
    Then $v = n - u \in N$ since $u \in U \subseteq N$.
    Therefore $v \in V \cap N$ and thus $n = u + v \in U \oplus (V \cap N)$.
  \end{proof}
  
  Using Zorn’s Lemma let $(L_i)_{i \in I}$ be a maximal family of simple submodules of $M$ such that the sum $\sum_{i \in I} L_i$ is direct.
  Let $D \subseteq M$ be a direct complement of
  \[
              S
    \coloneqq \bigoplus_{i \in I} L_i \,,
  \]
  i.e.\ $M = S \oplus D$.
  By construction $D$ contains no simple submodules.
  Let $d \in D$ with $d \neq 0$.
  Then $0 \subsetneq Rd \subseteq D$.
  By Zorn’s Lemma let $K \subseteq Rd$ be a maximal submodule.
  (Too see that this is possible notice that $Rd \cong R / \ker \phi$ for
  \[
            \phi
    \colon  R
    \to     Rd,
    \quad   r
    \mapsto rd \,.
  \]
  So the existence of a maximal submodule of $Rd$ is equivalent to the existance of a maximal ideal $I \subseteq R$ with $\ker \phi \subseteq I$.)
  By the claim there exists a direct complement $F$ of $K$ in $Rd$, i.e.\ $Rd = K \oplus F$.
  Because $K \subset Rd$ is maximal we find that $F \subseteq Rd$ is simple.
  Therefore $D$ contains a simple submodule.
  
  \ref{enum: direct sum of simple} $\implies$ \ref{enum: sum of simple}:
  This is clear.
\end{proof}


\begin{expls}
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      Let $k$ be a field.
      Since simple $k$-modules are the same as $1$-dimensional vector spaces every $k$-module is semisimple (this is equivalent to saying that every $k$-vector space has a basis).
    \item
      For a field $k$ let
      \[
                  R
        \coloneqq \left\{
                    \begin{pmatrix}
                      a & b \\
                      0 & c
                    \end{pmatrix}
                    \,\middle|\,
                    a, b, c \in k
                  \right\}
        \subseteq \Mat_2(k) \,.
      \]
      Then $k^2$ is not semisimple as an $R$-module since the only non-trivial submodule of $k^2$ is
      \[
        \{
          (x,0)
        \mid
          x \in k
        \} \,.
      \]
      To see this notice that
      \[
          \begin{pmatrix}
            a & b \\
            0 & c
          \end{pmatrix}
          \vect{x \\ y}
        = \vect{ax + by \\ cy},
      \]
      so if a submodule $M \subseteq k^2$ contains an element $(x,y) \in k^2$ with $y \neq 0$ then it contains both
      \begin{align*}
            \begin{pmatrix}
              0 & y^{-1} \\
              0 & 0
            \end{pmatrix}
            \vect{x \\ y}
        &=  \vect{1 \\ 0}
      \shortintertext{and}
            \begin{pmatrix}
              0 & 0 \\
              0 & y^{-1}
            \end{pmatrix}
            \vect{x \\ y}
        &=  \vect{0 \\ 1}
      \end{align*}
      and therefore $M = k^2$.
  \end{enumerate}
\end{expls}


\begin{lemma}\label{lemma: inherit semisimple}
  Let $R$ be a ring.
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      If $(M_i)_{i \in I}$ is a collection of semisimple $R$-modules then $\bigoplus_{i \in I} M_i$ is also semisimple.
    \item
      If $M$ is a semisimple $R$-module and $N \subseteq M$ a submodule then both $N$ and $M/N$ are also semisimple.
  \end{enumerate}
\end{lemma}
\begin{proof}
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      We can write each $M_i$ as $M_i = \bigoplus_{j \in J_i} L^j_i$ where $L^j_i \subseteq M_i$ is a simple submodule for all $j \in J_i$.
      Then
      \[
          \bigoplus_{i \in I} M_i
        = \bigoplus_{i \in I} \bigoplus_{j \in J_i} L^j_i
      \]
      is the direct sum of submodules and therefore semisimple.
    \item
      That $M/N$ is semisimple have we already shown in the claim of the proof of Proposition \ref{proposition: characterisation semisimple modules}.
      
      Since $M$ is semisimple we can write $M = \sum_{i \in I} L_i$ where $L_i \subseteq M$ is a simple submodule for all $i \in I$.
      Given the canonical projection
      \[
                \pi
        \colon  M
        \to     M / N
      \]
      we have that $\pi(L_i) \cong L_i$ or $\pi(L_i) = 0$ for all $i \in I$.
      For
      \[
                  J
        \coloneqq \{
                    i \in I
                  \mid
                    \pi(L_i) \neq 0
                  \}
      \]
      we therefore have
      \[
              M/N
        =     \pi(M)
        =     \pi\left( \sum_{i \in I} L_i \right)
        =     \sum_{j \in J} \pi(L_j)
        \cong \sum_{j \in J} L_j \,.
        \qedhere
      \]
  \end{enumerate}
\end{proof}


\begin{definition}
  Let $R$ be a ring and $M$ an $R$-module.
  For a simple $R$-module $E$ the submodule
  \[
              M_E
    \coloneqq \sum_{\substack{L \subseteq M \\ L \cong E}} L
  \]
  is the \emph{$E$-isotypical compotent of $M$}.
\end{definition}


The isotypical components of a semisimple module can also be described by using a decomposition into simple modules.


\begin{lemma}\label{lemma: isotypical component as direct sum}
  Let $R$ be a ring and $M$ and $R$-module with $M = \bigoplus_{i \in I} L_i$ where $L_i \subseteq M$ is a simple submodule for all $i \in I$.
  For every simple $R$-module $E$ we have
  \[
      M_E
    = \bigoplus_{\substack{i \in I \\ L_i \cong E}} L_i \,.
  \]
\end{lemma}
\begin{proof}
  Let $E$ be a simple $R$-module and
  \[
              J
    \coloneqq \{
                i \in I
              \mid
                L_i \cong E
              \} \,.
  \]
  It is clear that $\bigoplus_{j \in J} L_j \subseteq M_E$.
  To show the other inclusion it suffices to show that $F \subseteq \bigoplus_{j \in J} L_j$ for every simple submodule $F \subseteq M$ with $F \cong E$.
  Let $F$ be such a submodule.
  For over $i \in I$ we have the projection
  \[
                        f_i
    \colon              F
    \hookrightarrow     M
    \twoheadrightarrow  L_i
  \]
  with $x = \sum_{i \in I} f_i(x)$ for all $x \in F$ (where $f_i(x) = 0$ for all but finitely many $i \in I$).
  Since $f_i$ is always a homomorphism between simple modules it is either zero or an isomorphism.
  In particular we find that $f_i = 0$ for all $i \in I$ with $i \neq J$.
  Therefore $x = \sum_{j \in J} f_j(x) \subseteq \bigoplus_{j \in J} L_j$ for all $x \in F$.
\end{proof}


\begin{corollary}
  Let $R$ be a ring and $M$ a semisimple $R$-module.
  Given a decomposition $M = \bigoplus_{i \in I} L_i$ into simple submodules and a simple submodule $E \subseteq M$ there exists $i \in I$ with $L_i \cong E$.
\end{corollary}
\begin{proof}
  We have
  \begin{gather*}
              E
    \subseteq \sum_{\substack{L \subseteq M \\ L \cong E}} L
    =         M_E
    =         \bigoplus_{\substack{i \in I \\ L_i \cong E}} L_i \,,
  \shortintertext{so}
          \bigoplus_{\substack{i \in I \\ L_i \cong E}} L_i
    \neq  0 \,.
  \end{gather*}
  Therefore we have some $i \in I$ with $L_i \cong E$.
\end{proof}


\begin{definition}
  Let $R$ be a ring.
  Then
  \[
              \Irr(R)
    \coloneqq \{\text{isomorphism classes of simple $R$-modules}\} \,.
  \]
\end{definition}


Notice that $\Irr(R)$ is a set because for every simple $R$-module $E$ we have
\[
        E
  \cong R/I
\]
for some maximal ideal $I \subseteq R$.


\begin{corollary}\label{corollary: canonical decomposition semisimple module}
  Let $R$ be a ring and $M$ be a semisimple $R$-module.
  Then we have a canonical decomposition
  \[
      M
    = \bigoplus_{[E] \in \Irr(R)} M_E \,.
  \]
\end{corollary}


\begin{rem}
    Let $R$ be a ring, $M$ an $R$-module and $E$ a simple $R$-module.
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      $M_E$ does only depend on the isomorphism class of $E$.
    \item
      $M_E$ is a semisimple $R$-module (because it is the sum of simple modules).
    \item
      If $F \subseteq M_E$ is a simple $R$-module then $F \cong E$.
      To see this let $M_E = \sum_{i \in I} L_i$ where $L_i \subseteq M_E$ is a simple submodule with $L_i \cong E$ for all $i \in I$.
      Because $M_E$ is semisimple $F$ has a direct complement $C$ in $M_E$, so for every $i \in I$ we have a module homomorphism
      \[
                            f_i
        \colon              L_i
        \hookrightarrow     \sum_{i \in I} L_i
        =                   M_E
        =                   F \oplus C
        \twoheadrightarrow  F \,.
      \]
      Since the projection $F \oplus C \twoheadrightarrow F$ is non-zero we have $f_j \neq 0$ for some $j \in I$.
      Since $L_j$ and $F$ are simple the homomorphism $f_j \colon L_j \to F$ is an isomorphism.
      Therefore $F \cong L_j \cong E$.
    \item
      Let $F$ be a simple $R$-module.
      Then
      \[
          (M_E)_F
        = \begin{cases}
            M_E & \text{if } E \cong F \,,  \\
              0 & \text{otherwise} \,.
          \end{cases}
      \]
    \item
      Every homomorphism of $R$-modules $\varphi \colon M \to N$ induces a homomorphism
      \[
                \varphi_E
        \colon  M_E
        \to     N_E
      \]
      by restriction.
      Too see this simply notice that for every simple submodule $L \subseteq M$ the restriction
      \[
                \varphi_{|L}
        \colon  L
        \to     \varphi(L)
      \]
      is either zero (if $L \cap \ker \varphi \neq 0$ and consequently $L \subseteq \ker \varphi$) or an isomorphism (if $L \cap \ker \varphi = 0)$.
    \item
      If $U \subseteq M$ is a submodule then
      \[
          U_E
        = M_E \cap U \,.
      \]
      It is clear that
      \[
                  U_E
        =         \sum_{\substack{L \subseteq U \\ L \cong E}} L
        \subseteq \sum_{\substack{L \subseteq M \\ L \cong E}} L
        =         M_E \,.
      \]
      Because we have also $U_E \subseteq U$ we have $U_E \subseteq U \cap M_E$.
      On the other hand $M_E \cap U$ is a submodule of $M_E$ and thus $M_E \cap U \cong \bigoplus_{i \in I} E$ for some index set $I$.
      Since $M_E \cap U$ is also a submodule of $U$ we have $M_E \cap U \subseteq U_E$.
  \end{enumerate}
\end{rem}


\begin{definition}
  A ring $R$ is called \emph{semisimple} if it is semisimple as a (left) $R$-module, i.e.\ if $\prescript{}{R}{R}$ is semisimple.
\end{definition}


If $R$ is a semisimple ring then we have
\[
    R
  = \bigoplus_{[E] \in \Irr(R)} R_E
\]
as a (left) $R$-module by Corollary \ref{corollary: canonical decomposition semisimple module}.


\begin{definition}
  A ring $R$ is called \emph{simple} if $R \neq 0$ and $R = R_E$ for some simple $R$-module $E$.
  In particular $R$ is semisimple.
\end{definition}


\begin{definition}
  A $k$-algebra $A$ is called \emph{semisimple} (resp.\ \emph{simple}) if it is \emph{semisimple} (resp.\ \emph{simple}) as a ring.
\end{definition}


\begin{expls}
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      Fields are simple.
    \item
      For every finite group $G$ the group algebra $\Complex G$ is semisimple by Maschke’s Theorem.
    \item
      For a skew field $D$ the matrix ring $\Mat_n(D)$ is simple for all $n > 0$.
      To see this let
      \[
        C_i
        \coloneqq \{
                    A \in \Mat_n(D)
                  \mid
                    \text{ all except the $i$-th column are zero}
                  \} \,.
      \]
      Then
      \[
          \Mat_n(D)
        = \bigoplus_{i=1}^n C_i
      \]
      as a left $\Mat_n(D)$-modules with
      \[
        C_i \cong D^n
      \]
      as left $\Mat_n(D)$-modules for all $1 \leq i \leq n$.
      Since $D^n$ is simple as an left $\Mat_n(D)$-module the statement follows.
  \end{enumerate}
\end{expls}


\begin{proposition}
  Let $R$ be a semisimple ring (with $1$) and $M$ an $R$-module.
  Then $M$ is semisimple.
\end{proposition}
\begin{proof}
  Since $\prescript{}{R}{R}$ is semisimple and $M$ is the quotient of a free $R$-module (since $R$ is unitary) it follows directly from Lemma \ref{lemma: inherit semisimple} that $M$ is semisimple.
\end{proof}


\begin{lemma}\label{lemma: simple module of semisimple ring is direct summand}
  Let $R$ be a semisimple ring and $E$ a simple $R$-module.
  Then $F \cong E$ for some simple submodule $F \subseteq R$.
  More precisely:
  If $R = \bigoplus_{i \in I} L_i$ is a decomposition into simple submodules then $E \cong L_i$ for some $i \in I$.
\end{lemma}
\begin{proof}
  Because $E$ is cyclic there exists a surjective module homomorphism
  \[
                        \psi
    \colon              R
    \twoheadrightarrow  E
  \]
  For every $i \in I$ we have the module homomorphism
  \[
                        \phi_i
    \colon              L_i
    \hookrightarrow     \bigoplus_{i \in I} L_i
    =                   R
    \twoheadrightarrow  E \,.
  \]
  with $\psi = \bigoplus_{i \in I} \phi_i$.
  Since $\psi \neq 0$ we have $\phi_j \neq 0$ for some $j \in I$.
  Since $L_j$ and $E$ are both simple $\phi_j$ is already an isomorphism.
\end{proof}


\begin{corollary}\label{corollary: simple rings one simple module}
  Let $R$ be a simple ring.
  Then there is exactly one simple $R$-module up to isomorphism.
\end{corollary}
\begin{proof}
  Because $R$ is simple we have $R = M_F$ for some simple submodle $F \subseteq R$.
  For every simple $R$-module $E$ we have $E \cong F'$ for some simple $R$-module $F' \subseteq R$.
  Since $F' \subseteq M_F$ we have $F' \cong F$ and thus $E \cong F$.
\end{proof}


\begin{corollary}\label{corollary: D^n only simple M_n(D)-module}
  Let $D$ be a skew field.
  Then $D^n$ is the only simple $\Mat_n(D)$-module up to isomorphism.
\end{corollary}
\begin{proof}
  We know that $\Mat_n(D)$ is simple and $D^n$ a simple $\Mat_n(D)$-module.
  So the statement follows from Corollary \ref{corollary: simple rings one simple module}.
  (Notice that we have already seen that $\Mat_n(D) \cong \bigoplus_{i=1}^n C_i$ with $C_i \cong D^n$ for every $1 \leq i \leq n$ as $\Mat_n(D)$-modules.)
\end{proof}


\begin{lemma}\label{lemma: ring with 1 finite sum of submodules}
  Let $R$ be a semisimple ring (with $1$) and $R = \sum_{i \in I} M_i$ where $M_i \subseteq R$ is an $R$-submodule for every $i \in I$.
  Then $R = \sum_{j \in J} M_j$ for some finite subset $J \subseteq I$.
\end{lemma}
\begin{proof}
  We can write
  \[
      1
    = \sum_{i \in I} e_i
  \]
  with $e_i \in M_i$ for every $i \in I$ and $e_i = 0$ for all but finitely many $i \in I$. Let
  \[
              J
    \coloneqq \{i \in I \mid e_i \neq 0\} \,.
  \]
  Then
  \[
              \mc{I}
    \coloneqq \sum_{j \in J} M_i
  \]
  is an $R$-submodule of $R$, i.e.\ an left-ideal of $R$, with $1 \in \mc{I}$.
  Therefore $\mc{I} = R$.
\end{proof}


\begin{corollary}\label{lemma: semisimple ring with 1 only finitely many summands}
  Let $R$ be a semisimple ring (with $1$).
  Then $R$ is the direct sum of finitely many simple submodules.
\end{corollary}
\begin{proof}
  Because $R$ is semisimple we have $R = \bigoplus_{i \in I} L_i$ where $L_i \subseteq R$ is a simple $R$-submodule for every $i \in I$.
  By Lemma \ref{lemma: ring with 1 finite sum of submodules} there exists a finite subset $J \subseteq I$ with
  \[
      R
    = \sum_{j \in J} L_j
    = \bigoplus_{j \in J} L_j \,.
    \qedhere
  \]
\end{proof}





\section{(Jacobson) Density Theorems}


\begin{theorem}[1.\ Jacobson density theorem]
  Let $R$ be a ring (with $1$) and $M$ a semisimple $R$-module.
  Then $M$ is an $\End_R(M)$-module in the usual way, i.e.\
  \[
      f \cdot m
    = f(m)
    \text{ for all }
    f \in \End_R(M)\,,\,
    m \in M \,.
  \]
  We then have a map
  \[
            \Phi
    \colon  R
    \to     \End_{\End_R(M)}(M),
    \quad   r
    \mapsto (m \mapsto rm)
  \]
  and $\im \Phi$ is `dense' in $\End_{\End_R(M)}(M)$ in the following sense:
  Given
  \[
    f \in \End_{\End_R(M)}(M)
  \]
  and $m_1, \dotsc, m_s \in M$ there exists $x \in R$ such that
  \[
      x m_i
    = f(m_i)
    \text{ for all }
    1 \leq i \leq s \,.
  \]
\end{theorem}
\begin{proof}
  It is clear that $\Phi$ is well defined.
  
  We first show that $\im \Phi$ is `dense' in $\End_{\End_R(M)}(M)$ in the case that $s = 1$.
  For this let $m \in M$. Because $M$ is semisimple as an $R$-module we have
  \[
    M = Rm \oplus C
  \]
  as $R$-modules for some $R$-submodule $C \subseteq M$.
  Consider the projection (along this decomposition)
  \[
                        \pi
    \colon              M
    \twoheadrightarrow  Rm
    \hookrightarrow     M \,.
  \]
  It is clear that $\pi \in \End_R(M)$.
  So given $f \in \End_{\End_R(M)}(M)$ we have
  \[
      f \circ \pi
    = \pi \circ f \,.
  \]
  Because of this we have
  \[
        f(m)
    =   f(\pi(m))
    =   \pi(f(m))
    \in Rm \,.
  \]
  Therefore there exists $x \in R$ such that $f(m) = xm$.

  Now let $s \geq 2$. Let $f \in \End_{\End_R(M)}(M)$ and $m_1, \dotsc, m_s \in M$.
  We define
  \[
            \hat{f}
    \colon  M^s
    \to     M^s,
    \quad   (n_1, \dotsc, n_s)
    \mapsto (f(n_1), \dotsc, f(n_s)) \,.
  \]
  It is easy to see that $\hat{f} \in \End_{\End_R(M^s)}(M^s)$:
  Let $g \in \End_R(M^s)$.
  Using the usual isomorphism $\End_R(M^s) \cong \Mat_s(\End_R(M))$ we have $g_{ij} \in \End_R(M)$ for $1 \leq i,j \leq s$ such that
  \[
      g(n_1, \dotsc, n_s)
    = ( g_{11}(n_1) + \dotsb + g_{1s}(n_s),
        \dotsc,
        g_{s1}(n_1) + \dotsb + g_{ss}(n_s)  )
  \]
  for every $(n_1, \dotsc, n_s) \in M^s$.
  Because of this we have for every $(n_1, \dotsc, n_s) \in M^s$
  \begin{align*}
     &\,  \hat{f}( g(n_1, \dotsc, n_s) )  \\
    =&\,  \hat{f}( g_{11}(n_1) + \dotsb + g_{1s}(n_s),
                   \dotsc,
                   g_{s1}(n_1) + \dotsb + g_{ss}(n_s) ) \\
    =&\,  ( f(g_{11}(n_1) + \dotsb + g_{1s}(n_s)),
            \dotsc,
            f(g_{s1}(n_1) + \dotsb + g_{ss}(n_s)) ) \\
    =&\,  ( f(g_{11}(n_1)) + \dotsb + f(g_{1s}(n_s)),
            \dotsc,
            f(g_{s1}(n_1)) + \dotsb + f(g_{ss}(n_s))  ) \\
    =&\,  ( g_{11}(f(n_1)) + \dotsb + g_{1s}(f(n_s)),
            \dotsc,
            g_{s1}(f(n_1)) + \dotsb + g_{ss}(f(n_s))  ) \\
    =&\,  g( f(n_1), \dotsc, f(n_s) )
    =     g( \hat{f}(n_1, \dotsc, n_s )) \,.
  \end{align*}
  Since $f \in \End_{\End_R(M^s)}(M^s)$ we can use the previous case to find that there exists some $x \in R$ such that
  \[
    (f(m_1), \dotsc, f(m_s))
    = \hat{f}(m_1, \dotsc, m_s)
    = x (m_1, \dotsc, m_s)
    = (x m_1, \dotsc, x m_s) \,.
  \]
  Therefore $x m_i = f(m_i)$ for all $1 \leq i \leq s$.
\end{proof}


\begin{rem}
  In the special case that $M = R$ this results into an isomorphism
  \begin{align*}
                R
    &\cong      \End_{\End_R(R)}(R) \,, \\
                r
    &\mapsto    (m \mapsto rm) \,,  \\
                \varphi(1)
    &\mapsfrom  \varphi \,.
  \end{align*}
\end{rem}


\begin{corollary}[Density Theorem]
  Let $A$ be a $k$-algebra and $M$ a finite-dimensional semisimple $A$-module.
  Then the map
  \[
            \Phi
    \colon  A
    \to     \End_{\End_A(M)}(M)
  \]
  is surjective.
\end{corollary}
\begin{proof}
  Because we have $k \subseteq \End_A(M)$ we also have
  \[
              \End_{\End_A(M)}(M)
    \subseteq \End_k(M) \,.
  \]
  Let $m_1, \dotsc, m_s$ be a $k$-basis of $M$.
  For $\varphi \in \End_{\End_A(M)}(M)$ we have $a \in A$ with
  \[
      \varphi(m_i)
    = a m_i
    \text{ for all }
    1 \leq i \leq s
  \]
  by the 1.\ Jacobson density theorem.
  Let
  \[
            \psi
    \colon  M \to M,
    \quad   m
    \mapsto am \,.
  \]
  Because $m_1, \dotsc, m_s$ generates $M$ as a $k$-vector space and $\varphi$ and $\psi$ are $k$-linear it follows that $\varphi = \psi$.
\end{proof}


\begin{theorem}[2.\ Jacobson density theorem]
  Let $R$ be a ring (with $1$) and $N$ a simple $R$-module.
  Let $u_1, \dotsc, u_s \in N$ be linearly independent over $\End_R(N)$ and $v_1, \dotsc, v_n \in N$ arbitrary.
  Then there exists $r \in R$ with
  \[
      r u_i
    = v_i
    \text{ for all }
    1 \leq i \leq s \,.
  \]
  This is equivalent to saying that $N^s$ is generated by $(u_1, \dotsc, u_s)$ as an $R$-module.
\end{theorem}


\begin{proof}
  Let $x \coloneqq (u_1, \dotsc, u_s)$.
  Because $N^s$ is semisimple we have $N^s = Rx \oplus Q$ as $R$-modules for some $R$-submodule $Q \subseteq N^s$.
  Consider the projection (along this decomposition)
  \[
                        \pi
    \colon              N^s
    \twoheadrightarrow  Q
    \hookrightarrow     N^s \,.
  \]
  Then $\pi \in \End_R(N^s)$.
  $\pi$ is given as a matrix $(d_{ij})_{1 \leq i,j \leq s}$ with entries in $\End_R(N)$.
  Because $\pi(x) = 0$ and we have
  \[
      d_{i1} u_1 + \dotsc + d_{is} u_s
    = 0
    \text{ for all }
    1 \leq i \leq s \,.
  \]
  Since $u_1, \dotsc, u_s$ are linearly independent over $\End_R(N)$ we find that $d_{ij} = 0$ for all $1 \leq i,j \leq s$ and therefore $\pi = 0$.
  From this we find that $Q = 0$ and thus $Rx = N^s$.
\end{proof}


\begin{lemma}\label{lemma: k alg. closed and D/k f.d. division algebra then D=k}
  Let $k$ be an algebraically closed field and $D$ a finite-dimensional division algebra over $k$.
  Then $D = k$.
\end{lemma}
\begin{proof}
  Let $a \in D$ with $a \neq 0$.
  Because $\dim_k D < \infty$ we know that the elements $1$, $a$, $a^2$, $a^3$, \dots\ are linearly dependent.
  So there exists $p \in k[X]$ with $p(a) = 0$.
  Since $k$ is algebraically closed we have $p = \prod_{i=1}^n (X-a_i)$ for some $n \in \N$ and $a_1, \dotsc, a_n \in k$.
  Since
  \[
      0
    = p(a)
    = \prod_{i=1}^n (a-a_i)
  \]
  we find that $a = a_i$ for some $1 \leq i \leq n$ and thus $a \in k$.
\end{proof}


\begin{rem}
  That $k$ is algebraically closed is not only sufficient but also necessary.
  To see this let $k$ be a field which is not algebraically closed and $f \in k[X]$ such that $\deg f > 1$ and $f$ has no zeroes (in $k$).
  Then $L \coloneqq k[X]/(f)$ is a finite field extension $L/k$ with $L \supsetneq k$.
\end{rem}


\begin{lemma}[Schur’s Lemma for rings and algebras]
  Let $R$ be a ring and $M$ a simple $R$-module.
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      If $N$ is another simple $R$-module then every homomorphism of $R$-modules $f \colon M \to N$ is either zero or an isomorphism.
    \item
      $\End_R(M)$ is a skew field.
  \end{enumerate}
  If $R$ has the additional structure of a $k$-algebra we also have the following:
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*,resume]
    \item
      $\End_R(M)$ is a division algebra over $k$.
    \item
      If $k$ is algebraically closed and $\dim_k M < \infty$ then $\End_R(M) = k$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  The first three statements are clear, the third follows directly from Lemma \ref{lemma: k alg. closed and D/k f.d. division algebra then D=k}.
\end{proof}


\begin{rem}
  Schur’s Lemma for representation of groups can be derived from the one for algebras by the usual correspondence between representations of a group and modules over the group algebra.
\end{rem}


\begin{corollary}[Burnside’s Theorem on matrix algebras (coordinate free version)]
  Let $k$ be an algebraically closed field and $V$ a finite-dimensional $k$-vector space, $A \subseteq \End(V)$ a subalgebra such that $V$ is a simple $A$-module.
  Then $A = \End_k(V)$.
\end{corollary}
\begin{proof}
  From Schur’s Lemma we find that $\End_A(k^n) = k$.
  By the Density Theorem the inclusion
  \[
                    A
    \hookrightarrow \End_{\End_A(k^n)}(k^n)
    =               \End_k(k^n)
  \]
  is surjective.
  So $A = \End_k(k^n)$.
\end{proof}


\begin{corollary}[Burnside’s Theorem on matrix algebras (coordinate version)]
  Let $k$ be an algebraically closed field and $A \subseteq \Mat_n(k)$ a subalgebra, such that $k^n$ is a simple $A$-module.
  Then $A = \Mat_n(k)$.
\end{corollary}


It is perhaps interesting to notice that this could also be proven using the 2.\ Jacobson density theorem:


\begin{proof}
  From Schur’s Lemma we find that $\End_A(k^n) = k$.
  Therefore the standard basis $e_1, \dotsc, e_n$ of $k^n$ is linearly independent over $\End_A(k^n)$.
  Let $M \in \Mat_n(k)$ and let $m_i \in k^n$ be the $i$-th column vector of $M$ for all $1 \leq i \leq n$.
  By the 2.\ Jacobson density theorem there exists $M' \in A$ with $M' e_i = m_i$ for all $1 \leq i \leq n$.
  Since $M' e_i$ is the $i$-th column vector of $M'$ we have $M = M' \in A$.
\end{proof}


\begin{corollary}\label{corollary: simple algebra module surjective algebra homo}
  Let $k$ be an algebraically closed field and $A$ a  $k$-algebra.
  For a finite-dimensional $A$-module $M$ the following are equivalent:
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      $M$ is a simple $A$-module.
    \item
      The corresponding algebra homomorphism $\Phi \colon A \to \End_k(M)$ is surjective.
  \end{enumerate}
\end{corollary}
\begin{proof}
  If $M$ is simple as an $A$-module it is simple as a module over $\im \Phi$.
  By Burnside’s Theorem on matrix algebras we find that $\im \Phi = \End_k(V)$.
  So $\Phi$ is surjective.
  
  Suppose $\Phi$ is surjective.
  Let $m \in M$ with $m \neq 0$.
  For every $m' \in M$ there exists $\varphi \in \End_k(M)$ with $\varphi(m) = m'$.
  Since $\Phi$ is surjective there exists $a \in A$ with $\Phi(a) = \varphi$ and thus
  \[
      am
    = \Phi(a)(m)
    = \varphi(m)
    = m \,.
  \]
  Therefore $Am = M$.
\end{proof}


\begin{corollary}\label{corollary: dimension simple algebra modules}
  Let $k$ be an algebraically closed field, $A$ a $k$-algebra and $M$ a finite-dimensional simple $A$-module.
  Then
  \[
          (\dim_k M)^2
    \leq  \dim_k A \,.
  \]
\end{corollary}
\begin{proof}
  By Corollary \ref{corollary: simple algebra module surjective algebra homo} the corresponding algebra homomorphism
  \[
            \Phi
    \colon  A
    \to     \End_k(M)
  \]
  is surjective. Therefore
  \[
          (\dim_k M)^2
    =     \dim_k \End_k(M)
    =     \dim_k \im \Phi
    \leq  \dim_k A \,.
    \qedhere
  \]
\end{proof}


If $k$ is algebraically closed and $A$ a $k$-algebra we know that for every finite-dimensional simple $A$-module $M$ the corresponding algebra homomorphism $A \to \End_k(M)$ is surjective.
We can strengthen this result.


\begin{lemma}\label{lemma: map into sum endomorphisms surjective}
  Let $k$ be an algebraically closed field, $A$ a $k$-algebra and $M_1, \dotsc, M_s$ finite-dimensional simple $A$-modules which are pairwise non-isomorphic.
  For every $1 \leq i \leq s$ we have a surjective algebra homomorphism
  \[
                        \phi_i
    \colon              A
    \twoheadrightarrow  \End_k(M_i) \,.
  \]
  The map
  \[
              \Phi
    \coloneqq \bigoplus_{i=1}^r \phi_i
    \colon    A
    \to       \bigoplus_{i=1}^r \End_k(M_i)
  \]
  is also surjective.
\end{lemma}
\begin{proof}
  We set
  \[
    M \coloneqq \bigoplus_{i=1}^r M_i \,.
  \]
  Because the $M_i$ are simple and pairwise non-isomorphic we know from Schur’s Lemma that
  \begin{align*}
                \End_A(M)
    &\cong      \bigoplus_{i=1}^r \End_A(M_i), \\
                \varphi_1 \oplus \dotsb \oplus \varphi_r
    &\mapsfrom  (\varphi_1, \dotsc, \varphi_r)
  \end{align*}
  Because $k$ is algebraically closed and the $M_i$ are finite-dimensional and simple Schur’s Lemma also tells us that
  \[
              \End_A(M_i)
    \cong     k,
    \quad     \lambda \id_{M_i}
    \mapsfrom \lambda
  \]
  for every $1 \leq i \leq r$.
  Combining these isomorphisms we find that
  \begin{align*}
                \End_A(M)
    &\cong      k^r \\
                (
                          (m_1, \dotsc, m_r)
                  \mapsto (a_1 m_1, \dotsc, a_r m_r)
                )
    &\mapsfrom  (a_1, \dotsc, a_r).
  \end{align*}
  We therefore have
  \[
      \End_{\End_A(M)}(M)
    = \End_{k^r}(M)
  \]
  where $(a_1, \dotsc, a_r) \in k^r$ acts on $(m_1, \dotsc, m_r) \in M$ as
  \[
      (a_1, \dotsc, a_n)(m_1, \dotsc, m_r)
    = (a_1 m_1, \dotsc, a_r m_r) \,.
  \]
  It is clear that
  \begin{align*}
                \End_{k^r}(M)
    &\cong      \bigoplus_{i=1}^r \End_k(M_i) \,, \\
                \varphi_1 \oplus \dotsb \oplus \varphi_r
    &\mapsfrom  (\varphi_1, \dotsc, \varphi_r) \,.
  \end{align*}
  By the Density Theorem we find that the map
  \[
            A
    \to     \End_{k^r}(M) \,,
    \quad   a
    \mapsto (m \mapsto am)
  \]
  is surjective.
  Since the diagram
  \begin{center}
    \begin{tikzpicture}
      \node (A) {$A$};
      \node (End kr) [below left = 4em and 2em of A] {$\End_{k^r}(M)$};
      \node (plus End k) [below right = 4em and 2em of A] {$\bigoplus_{i=1}^r \End_k(M_i)$};
      \draw[->>] (A) to (End kr);
      \draw[->] (A) to node[above right] {$\Phi$} (plus End k);
      \draw[double equal sign distance] (End kr) to node[above] {$\sim$} (plus End k);
    \end{tikzpicture}
  \end{center}
  commutes, we find that $\Phi$ is surjective.
\end{proof}


Applying our results about finite-dimensional simple modules over algebras to group algebras gives us corresponding statements about representations of groups.


\begin{lemma}\label{lemma: equivalence to irreducible}
  Let $G$ be a group and $V \neq 0$ a finite-dimensional representation of $G$ over an algebraically closed field $k$. Then the following are equivalent:
  \begin{enumerate}[label=\emph{\roman*)},leftmargin=*]
    \item \label{enum: V irreducible}
      $V$ is irreducible.
    \item \label{enum: V simple kG-module}
      $V$ is simple as a $kG$-module.
    \item \label{enum: surjective algebra homo}
      The algebra homomorphism
      \[
                \Phi
        \colon  kG
        \to     \End_k(V) \,,
        \quad   a
        \mapsto (v \mapsto av)
      \]
      is surjective.
  \end{enumerate}
\end{lemma}
\begin{proof}
  The equivalence of \ref{enum: V irreducible} and \ref{enum: V simple kG-module} is clear.
  The equivalence of \ref{enum: V simple kG-module} and \ref{enum: surjective algebra homo} follows directly from Corollary \ref{corollary: simple algebra module surjective algebra homo}.
\end{proof}


\begin{corollary}
  Let $G$ be a finite group and $V$ a finite-dimensional irreducible representation of $G$ over an algebraically closed field $k$.
  Then
  \[
          \left( \dim_k V \right)^2
    \leq |G| \,.
  \]
\end{corollary}
\begin{proof}
  $V$ is a simple $kG$-module, so by Corollary \ref{corollary: dimension simple algebra modules}
  \[
          (\dim_k V)^2
    \leq  \dim_k kG
    =     |G| \,.
    \qedhere
  \]
\end{proof}


\begin{lemma}\label{lemma: modules over direct sum of algebras}
  Let $R_i$, $1 \leq i \leq n$ be rings (with $1$) and $R \coloneqq \prod_{i=1}^n R_i$.
  For $1 \leq i \leq n$ let
  \[
      1_i
    = (\delta_{ij})_{1 \leq j \leq r}
    \in R
  \]
  be the unit of $R_i \subseteq R$, i.e.\
  \[
      (1_i)_j
    = \begin{cases}
        1 & \text{if } j = i \,,  \\
        0 & \text{otherwise} \,.
      \end{cases}
  \]
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      $R$ is unitary with $1 = \sum_{i=1}^n 1_i$ and for all $1 \leq i,j \leq n$ we have $1_i 1_j = \delta_{ij}$.
    \item
      If $M$ is an $R$-module then $M_i \coloneqq 1_i M$ is an $M_i$-module by restriction and for every $1 \leq j \leq n$ with $i \neq j$ we have $R_j M_i = 0$.
    \item
      If $M_i$ is an $R_i$-module for every $1 \leq i \leq n$ then $M \coloneqq M_1 \oplus \dotsb \oplus M_n$ is an $R$-module via
      \[
          (r_1, \dotsc, r_n) (m_1, \dotsc, m_n)
        = (r_1 m_1, \dotsc, r_n m_n) \,.
      \]
    \item
      Let $M$ be an $R$-module and $M_i \coloneqq 1_i M$ for every $1 \leq i \leq n$.
      Then the abelian subgroup \mbox{$\sum_{i=1}^n M_i \subseteq M$} is an $R$-submodule.
      We have $\sum_{i=1}^n M_i = M$ and the sum is direct, so
      \[
        M = M_1 \oplus \dotsb \oplus M_r \,.
      \]
    \item
      An $R$-module $M \neq 0$ is simple if and only if there exists an (unique) \mbox{$1 \leq i \leq n$} such that for every $1 \leq j \leq n$
      \[
        1_j M
        = \begin{cases}
            \text{a simple $R_j$-module} & \text{if } i = j \,, \\
                                       0 & \text{otherwise} \,.
          \end{cases}
      \]
  \end{enumerate}
\end{lemma}
\begin{proof}
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      This is clear.
    \item
      It is clear that $1_i M \subseteq M$ is an abelian subgroup. We have
      \[
          R_i 1_i
        = 1_i R_i
        = 1_i R
      \]
      and therefore
      \[
                  R_i 1_i M
        =         1_i R_i M
        =         1_i R M
        \subseteq 1_i M \,,
      \]
      and for every $m \in M$ we have
      \[
          1_i (1_i m)
        = (1_i 1_i) m
        = 1_i m \,.
      \]
      For every $1 \leq j \leq n$ with $j \neq i$ we have
      \[
          R_j M_i
        = (R 1_j) (1_i M)
        = R \underbrace{1_j 1_i}_{=0} M
        = 0 \,.
      \]
    \item
      This is clear.
    \item
      We set
      \[
        M' \coloneqq \sum_{i=1}^n M_i \,.
      \]
      $M'$ is an $R$-submodule since
      \[
          R M'
        = R \sum_{i=1}^n M_i
        = \sum_{i=1}^n R M_i
        = \sum_{i=1}^n R 1_i M_i
        = \sum_{i=1}^n R_i M_i
        = \sum_{i=1}^n M_i
        = M' \,.
      \]
      To see that $M = M'$ notice that
      \[
          M
        = 1 M
        = \left( \sum_{i=1}^n 1_i \right) M
        = \sum_{i=1}^n (1_i M)
        = \sum_{i=1}^n M_i
        = M' \,.
      \]
      To see that this sum is direct let $m = \sum_{i=1}^n m_i = \sum_{i=1}^n m'_i \in M$ with $m_i, m'_i \in M_i$ for every $1 \leq i \leq n$.
      Then we have for every $1 \leq i \leq n$
      \[
          1_i m
        = 1_i \sum_{j=1}^n m_j
        = \sum_{j=1}^n 1_i m_j
        = m_i
      \]
      and in the same way $1_i m = m'_i$, so $m_i = m'_i$ for every $1 \leq i \leq n$.
    \item
      We can write $M$ as $M = M_1 \oplus \dotsb \oplus M_n$ where $M_i \coloneqq 1_i M$ is an $R_i$-module for every $1 \leq i \leq n$.
      From the previous observations we find that we have a bijection
      \[
                S_1 \times \dotsb \times S_n
        \to     S,
        \quad   (N_1, \dotsb, N_n)
        \mapsto N_1 \oplus \dotsb \oplus N_n \,,
      \]
      where $S_i$ is the set of $R_i$-submodules of $M_i$ for every $1 \leq i \leq n$ and $S$ is the set of $R$-submodules of $M$.
      Since $M$ is simple we have $|S| = 2$, so
      \[
          2
        = |S|
        = |S_1 \times \dotsb \times S_n|
        = |S_1| \dotsm |S_n| \,.
      \]
      So we have $|S_i| = 2$ for exactly one $1 \leq i \leq n$ and $|S_j| = 1$ for $j \neq i$.
      So $M_i$ is a simple $R_i$-module and $M_j = 0$ for $j \neq i$.
    \qedhere
  \end{enumerate}
\end{proof}


\begin{corollary}\label{corollary: simple modules over product of matrix algebras}
  Let $R$ be a ring
  \[
                  A
    \cong         \Mat_{n_1}(D_1)
          \times  \dotsb
          \times  \Mat_{n_r}(D_r)
  \]
  for some $r \geq 1$, $n_1, \dotsc, n_r \geq 1$ and skew fields $D_1, \dotsc, D_r$.
  Then there are up to isomorphism exactly $r$ simple $R$-modules, namely $D_1^{n_1}, \dotsc, D_r^{n_r}$, where $(B_1, \dotsc, B_r) \in R$ acts on $x \in D_i^{n_i}$ by
  \[
      (B_1, \dotsc, B_r) x
    =  B_i x \,.
  \]
\end{corollary}
\begin{proof}
  This follows immediately from Corollary \ref{corollary: D^n only simple M_n(D)-module} and Lemma \ref{lemma: modules over direct sum of algebras}.
\end{proof}


\begin{proposition}\label{proposition: simple modules over finite-dimensional algebras}
  Let $k$ be a field and $A$ a finite-dimensional $k$-algebra.
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      Every simple $A$-module is finite-dimensional.
      More precisely
      \[
        \dim_k V \leq \dim_k A
      \]
      for every simple $A$-module $V$.
    \item
      If $k$ is algebraically closed there are (up to isomorphism) only finitely many simple $A$-modules. More precisely
      \[
        |\Irr(A)| \leq \dim_k A \,.
      \]
  \end{enumerate}
\end{proposition}
\begin{proof}
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      Since $V$ is simple it is cyclic, so we have a surjective homomorphism of $A$-modules
      \[
                            \varphi
        \colon              A
        \twoheadrightarrow  V \,.
      \]
      Because $\varphi$ is $k$-linear we find that $\dim_k V \leq \dim_k A$.
    \item
      Let $V_1, \dotsc, V_r$ be pairwise non-isomorphic simple $A$-modules. By Lemma \ref{lemma: map into sum endomorphisms surjective} we find that the map
      \[
            A
        \to \bigoplus_{i=1}^r \End_k(V_i)
      \]
      is surjective. Therefore
      \[
              r
        \leq  \sum_{i=1}^r \dim_k \End_k(V_i)
        \leq  \dim_k A \,.
        \qedhere
      \]
  \end{enumerate}
\end{proof}


\begin{definition}
  Let $R$ be a ring. Then
  \[
              Z(R)
    \coloneqq \{
                r \in R
              \mid
                rs = sr
                \text{ for every }
                s \in R
              \}
  \]
  is the \emph{center of $R$}.
\end{definition}


\begin{lemma}
  For every ring $R$ the center $Z(R)$ is a commutative subring.
  For every $k$-algebra $A$ the center $Z(A)$ is a commutative subalgebra.
\end{lemma}
\begin{proof}
  This is clear.
\end{proof}


\begin{definition}
  Let $A$ be a $k$-algebra.
  Then the \emph{commutator of $A$} is defined as
  \[
              [A,A]
    \coloneqq \vspan_k  \{
                          ab - ba
                        \mid
                          a, b \in A
                        \}
    \subseteq A \,.
  \]
\end{definition}


\begin{expl}
  For every field $k$ and $n \geq 1$ we set
  \[
    \Sl_n(k) \coloneqq [\Mat_n(k), \Mat_n(k)]
  \]
  We then have
  \[
      \Sl_n(k)
    = \ker \tr
    = \{
        M \in \Mat_n(k)
      \mid
        \tr M = 0
      \} \,.
  \]
  \begin{proof}
    For all $A, B \in \Mat_n(k)$ we have
    \[
        \tr(AB - BA)
      = \tr(AB) - \tr(BA)
      = \tr(AB) -0\tr(AB)
      = 0 \,.
    \]
    Since these elements generate $\Sl_n(k)$ as a $k$-vector space and $\tr$ is $k$-linear we find that $\Sl_n(k) \subseteq \ker \tr$.
    
    To show the other inclusion let $(E_{ij})_{1 \leq i,j \leq n}$ be the usual $k$-basis of $\Mat_n(k)$ (where $E_{ij}$ maps $e_j$ to $e_i$ for all $1 \leq i,j \leq n)$.
    It is clear that the matrices $E_{ij}$ for $i \neq j$ together with the matrices $E_{ii}-E_{i+1,i+1}$ for $1 \leq i \leq n-1$ form a $k$-basis of $\ker \tr$.
    For all $1 \leq i,j \leq n$ with $i \neq j$ we have
    \[
          E_{ij}
      =   E_{ii} E_{ij} - \underbrace{E_{ij} E_{ii}}_{=0}
      =   [E_{ii}, E_{ij}]
      \in \Sl_n(k)
    \]
    and for all $1 \leq i \leq n-1$ we have
    \[
          E_{ii} - E_{i+1,i+1}
      =   E_{i,i+1} E_{i+1,i} - E_{i+1,i} E_{i,i+1}
      =   [E_{i,i+1}, E_{i+1,i}]
      \in \Sl_n(k) \,,
    \]
    so $\ker \tr \subseteq \Sl_n(k)$.
  \end{proof}
\end{expl}


\begin{rem}
  Let $k$ be any field.
  One can show that for every matrix $C \in \Mat_n(k)$ with $\tr C = 0$ we have matrices $A, B \in \Mat_n(k)$ with $C = [A,B]$.
  So
  \[
      \Sl_n(k)
    = \{
        [A,B]
      \mid
        A, B \in \Mat_n(k)
      \} \,.
  \]
\end{rem}


\begin{lemma}
  Let $A$ and $B$ be $k$-algebras. Then
  \[
      [A \oplus B, A \oplus B]
    = [A,A] \oplus [B,B].
  \]
  as $k$-vector subspaces of $A \oplus B$.
\end{lemma}
\begin{proof}
  For all $a, a' \in A$ and $b, b' \in B$ we have
  \begin{align*}
        [(a,b),(a',b')]
    &=  (a,b)(a',b') - (a',b')(a,b)
     =  (aa',bb') - (a'a, b'b) \\
    &=  (aa'-a'a, bb' - b'b)
     =  ([a,a'], [b,b']) \,.
  \end{align*}
  Therefore
  \begin{align*}
        [A \oplus B, A \oplus B]
    &=  \vspan_k  \{
                    [(a,b), (a',b')]
                  \mid
                    (a,b), (a',b') \in A \oplus B
                  \} \\
    &= \vspan_k \{
                  ([a,a'], [b,b'])
                \mid
                  a, a' \in A
                  \text{ and }
                  b, b' \in B
                \} \\
    &=  \left(
          \vspan_k \{ [a,a'] \mid a, a' \in A \}
        \right)
        \oplus
        \left(
          \vspan_k \{ [b,b'] \mid b, b' \in B \}
        \right) \\
    &= [A,A] \oplus [B,B] \,.
    \qedhere
  \end{align*}
\end{proof}


\begin{corollary}\label{corollary: commutator product of matrix algebras}
  Let $r \geq 1$ and $n_1, \dots, n_r \geq 1$. For
  \[
    A \coloneqq \Mat_{n_1}(k) \oplus \dotsb \oplus \Mat_{n_r}(k)
  \]
  we then have
  \[
      [A,A]
    = \Sl_{n_1}(k) \oplus \dotsb \oplus \Sl_{n_r}(k) \,.
  \]
\end{corollary}





\section{Theorem of Artin--Wedderburn}


\begin{definition}
  Let $R$ be a ring. Then the ring $R^\op$ is defined by taking the underlying additive group of $R$ and reversing the multiplication order, i.e.\ if for the multiplication $\cdot$ in $R$ and the multiplication $*$ in $R^\op$ we have
  \[
      a * b
    = b \cdot a
    \text{ for all }
    a, b \in R^\op \,.
  \]
\end{definition}


\begin{rem}
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      For every ring $R$ we have $\left( R^\op \right)^\op = R$.
    \item
      A ring $R$ is commutative if and only if $R = R^\op$.
    \item
      A ring $R$ is unitary if and only if $R^\op$ is unitary.
    \item
      If $D$ is a skew field then $D^\op$ is also a skew field.
    \item
      For a collectios of rings $R_i$, $i \in I$ we have
      \[
          \left( \prod_{i \in I} R_i \right)^\op
        = \prod_{i \in I} R_i^\op
      \]
      and
      \[
          \left( \bigoplus_{i \in I} R_i \right)^\op
        = \bigoplus_{i \in I} R_i^\op \,.
      \]
  \end{enumerate}
\end{rem}


\begin{expl}
  Let $D$ be a skew field and $n \geq 1$.
  Then we have an isomorphism of rings
  \[
            \Mat_n(D)
    \cong   \Mat_n\left( D^\op \right)^\op,
    \quad   A
    \mapsto A^T \,.
  \]
  For a field $k$ this gives us an isomorphism
  \[
            \Mat_n(k)
    \cong   \Mat_n(k)^\op,
    \quad   A
    \mapsto A^T \,.
  \]
\end{expl}


For a ring $R$ there is a strong connection between left $R$-modules and right $R^\op$-modules.


\begin{proposition}\label{proposition: opposite modules}
  Let $R$ be a ring.
  We have a 1:1-correspondence between the left $R$-modules and $R^\op$-modules, where for a left $R$-module $M$ the corresponding right $R^\op$-module $M^\op$ is defined as
  \[
              m \bullet r
    \coloneqq r \cdot m
    \text{ for every }
    m \in M^\op \,,\,
    r \in R^\op \,,
  \]
  where $\bullet$ denotes the multiplication of $R^\op$ on $M^\op$ and $\cdot$ the multiplication of $R$ on $M$.
\end{proposition}
\begin{proof}
  <Insert obvious calculations here>.
\end{proof}


\begin{lemma}\label{lemma: End_R(R) = Rop}
  Let $R$ be a ring (with $1$).
  Let $\cdot$ denote the multiplication in $R$ and $*$ the multiplication in $R^\op$.
  Then we have an isomorphism of rings
  \[
              \End_R(R)
    \cong     R^\op,
    \quad     (s \mapsto s \cdot r)
    \mapsfrom r \,.
  \]
\end{lemma}


The Lemma basically states that the $\Z$-homomorphisms of $R$ which are compatible with the left multiplication are given by right multiplication.


\begin{proof}
  Let
  \[
            \varphi
    \colon  R^\op
    \to     \End_R(R),
    \quad   r
    \mapsto (s \mapsto s \cdot r) \,.
  \]
  We first show that $\varphi$ is well-defined:
  Notice that $(s \mapsto s \cdot r)$ is $\Z$-linear for every $r \in R^\op$ by the distributivity of $\cdot$ and $R$-linear by the associativity of $\cdot$.
  
  To see that $\varphi$ is a ring-homomorphism notice that $\varphi(1) = \id_R$ and for all $r, r' \in R^\op$ and $s \in R$
  \begin{align*}
        \varphi(r+r')(s)
    &=  s \cdot (r + r')
     =  s \cdot r + s \cdot r' \\
    &=  \varphi(r)(s) + \varphi(r')(s)
     =  (\varphi(r)+\varphi(r'))(s)
  \end{align*}
  and
  \begin{align*}
        \varphi(r * r')(s)
    &=  s \cdot (r * r')
     =  s \cdot (r' \cdot r) \\
    &=  (s \cdot r') \cdot r
     =  \left(\varphi(r) \circ \varphi(r')\right)(s) \,.
  \end{align*}
  
  That $\varphi$ is injective is clear, since for every $r \in \ker \varphi$
  \[
      0
    = \varphi(r)(1)
    = 1 \cdot r
    = r \,.
  \]
  To see that it is surjective let $f \in \End_R(R)$ and set $r \coloneqq f(1)$.
  For every $s \in R$ we then have
  \[
      f(s)
    = f(s \cdot 1)
    = s \cdot f(1)
    = s \cdot r
    = \varphi(r)(s) \,,
  \]
  and thus $f = \varphi(r)$.
\end{proof}


Let $D$ be a skew field.
Becaus $D^n$ is a simple $\Mat_n(D)$-module we know from Schur’s Lemma that $\End_{\Mat_n(D)}(D^n)$ is a skew field.
We would like to know how $D$ and $\End_{\Mat_n(D)}(D^n)$ are related.
We know from linear algebra that for every field $k$ we have
\[
        \End_{\Mat_n(k)}(k^n)
  \cong k.
\]
From Lemma \ref{lemma: End_R(R) = Rop} we also know that in the case $n = 1$. 
\[
  \End_D(D) \cong D^\op
\]
These observations lead to the following Lemma:


\begin{lemma}
  Let $D$ be a skew field and $n \geq 1$. Then
  \[
              \End_{\Mat_n(D)}\left(D^n\right)
    \cong     D^\op,
    \quad     \left(
                        \vect{x_1 \\ \vdots \\ x_n}
                \mapsto \vect{x_1 d \\ \vdots \\ x_n d}
              \right)
    \mapsfrom d
  \]
  as rings.
\end{lemma}
\begin{proof}
  By $\cdot$ we denote the multiplication in $D$ and by $*$ the multiplication in $D^\op$.
  For all $d \in D$, $d' \in D^\op$ and $x = (x_1, \dotsc, x_n) \in D^n$ we write
  \[
              d x
    \coloneqq (d x_1, \dotsc, d x_n)
    \qquad \text{ and } \qquad
              x d'
    \coloneqq (x_1 d', \dotsc, x_n d'). 
  \]
  We also define
  \[
    \pi_i \colon D^n \to D
  \]
  as the canonical projection for every $1 \leq i \leq n$.
  It is clear that $\pi_i$ is $D$-linear for every $1 \leq i \leq n$ where we see $D^n$ and $D$ as left $D$-modules in the usual way.
  By $e_1, \dotsc, e_n$ we denote the standard basis of $D^n$ (as a left $D$-module).
  
  We define
  \[
            \varphi
    \colon  D^\op
    \to     \End_{\Mat_n(D)}\left( D^n \right),
    \quad   d
    \mapsto (x \mapsto x d) \,.
  \]
  It is clear that $\varphi$ is well-defined.
  It is clear that $\varphi$ is additive.
  That it is also multiplicative (and thus a ring homomorphism) follow from simple calculation:
  For all $d, d' \in D^\op$ and $x \in D^n$ we have
  \[
      \varphi(d * d')(x)
    = x (d * d')
    = x (d' \cdot d)
    = (x d') d
    = \left( \varphi(d) \circ \varphi(d') \right)(x) \,.
  \]
  
  It is also easy to see that $\varphi$ is injective:
  For $d, d' \in D^\op$ with $\varphi(d) = \varphi(d')$ we have
  \[
      d
    = \pi_1(e_1 d)
    = \pi_1(\varphi(d)(e_1))
    = \pi_1(\varphi(d')(e_1))
    = \pi_1(e_1 d')
    = d' \,.
  \]
  
  All that’s left to show is that $\varphi$ is surjective.
  For this let $f \in \End_{\Mat_n(D)}(D^n)$.
  $f$ is $D$-linear, because for all $d \in D$ and $x = (x_1, \dotsc, x_n) \in D^n$
  \[
      f(dx)
    = f( \diag(d, \dotsc, d) x)
    = \diag(d, \dotsc, d) f(x)
    = d f(x) \,.
  \]
  For every $1 \leq i \leq n$ we set $d_i \coloneqq \pi_i(f(e_i))$.
  We then have for every $1 \leq i \leq n$
  \[
      f(e_i)
    = f(E_{ii} e_i)
    = E_{ii} f(e_i)
    = (0, \dotsc, d_i, \dotsc, 0)
    = e_i d_i 
  \]
  and therefore for every $x = (x_1, \dotsc, x_n) \in D^n$
  \begin{align*}
        f(x)
    &=  f(x_1 e_1 + \dotsb + x_n e_n)       \\
    &=  f(x_1 e_1) + \dotsb + f(x_n e_n)    \\
    &=  x_1 f(e_1) + \dotsb + x_n f(e_n)    \\
    &=  x_1 e_1 d_1 + \dotsb + x_n e_n d_n  \\
    &=  (x_1 d_1, \dotsc, x_n d_n)
  \end{align*}
  For every $1 \leq i,j \leq n$ we have
  \begin{align*}
        d_i
    &=  \pi_i(e_i d_i)
     =  \pi_i(f(e_i))
     =  \pi_i(f(E_{ij} e_j)) \\
    &=  \pi_i(E_{ij} f(e_j))
     =  \pi_i(E_{ij} e_j d_j)
     =  \pi_i(e_i d_j)
     =  d_j \,.
  \end{align*}   
  This shows that $f = \varphi(d)$ for $d \coloneqq d_1 = \dotsb = d_n$.
\end{proof}


\begin{theorem}[Artin--Wedderburn]
  Let $R$ be a semisimple ring (with $1$). Then
  \[
    R \cong \Mat_{n_1}(D_1) \times \dotsb \times  \Mat_{n_r}(D_r)
  \]
  for $r \geq 1$, $n_1, \dotsc, n_r \geq 1$ and skew fields $D_1, \dotsc, D_r$.
  Moreover $r$ is unique, $(n_1,D_1), \dotsc, (n_r,D_r)$ are unique up to permutation and isomorphism of the $D_i$.
  
  More precisely:
  If $R \cong n_1 V_1 \oplus \dotsb \oplus n_r V_r$ as $R$-modules for $n_1, \dotsc, n_r \geq 1$ and pairwise non-isomorphic simple $R$-modules $V_1, \dotsc, V_r$ then
  \[
    R \cong \Mat_{n_1}(\End_R(V_1)^\op) \times \dotsb \times \Mat_{n_r}(\End_R(V_r)^\op) \,.
  \]
\end{theorem}


Notice that by Corollary \ref{corollary: simple modules over product of matrix algebras} it follows that a ring of the above form has exactly $r$ simple modules up to isomorphism, namely $D_1^{n_1}, \dotsc, D_r^{n_r}$.


\begin{corollary}
  Let $R$ be a semisimple ring (with $1$) and $M$ a faithful $R$-module, i.e.\ $rm = 0$ for every $r \in R$ implies $m = 0$.
  Then the isotypical components of $M$ are all nonzero.
  In particular $M$ contains every simple $R$-module up to isomorphism.
\end{corollary}
\begin{proof}
  By Artin--Wedderburn we have
  \[
    R \cong M_{n_1}(D_1) \times \dotsb \times M_{n_s}(D_s)
  \]
  for $s \geq 1$, $n_1, \dotsc, n_s \geq 1$ and skew field $D_1, \dotsc, D_s$.
  Then $D_1^{n_1}, \dotsc, D_r^{n_r}$ are a complete set of representatives of $\Irr(R)$, where $(A_1, \dotsc, A_s) \in R$ acts on $x \in D_i^{n_i}$ by $(A_1, \dotsc, A_n) \cdot x = A_i x$.
  Since $R$ is semisimple so is $M$ and thus we have a decomposition $M \cong \bigoplus_{i=1}^s M_{D_i^{n_i}}$ into isotypical components.
  Suppose that $M_{D_i^{n_i}} = 0$ for some $1 \leq i \leq s$.
  Then every element $A \in M_{n_i}(D_i) \subseteq R$ acts by multiplication with zero on $M$, which contradicts the faithfulness of $M$.
  Thus the isotypical components $M_{D_i^{n_i}}$ are all nonzero.
\end{proof}




\begin{corollary}
  Let $R$ be a semisimple ring (with $1$).
  Then $R^\op$ is also semisimple.
\end{corollary}
\begin{proof}
  By Artin--Wedderburn we have
  \[
    R \cong \Mat_{n_1}(D_1) \times \dotsm \times \Mat_{n_r}(D_r)
  \]
  for $r \geq 1$, $n_1, \dotsc, n_r \geq 1$ and skew fields $D_1, \dotsc, D_r$.
  Therefore
  \begin{align*}
            R^\op
    &\cong  \left( \Mat_{n_1}(D_1) \times \dotsm \times \Mat_{n_r}(D_r) \right)^\op \\
    &=      \Mat_{n_1}(D_1)^\op \times \dotsm \times \Mat_{n_r}(D_r)^\op \\
    &=      \Mat_{n_1}\left( D_1^\op \right) \times \dotsm \times \Mat_{n_r}\left( D_r^\op \right).
  \end{align*}
  Since $D_1^\op, \dotsc, D_r^\op$ are skew fields we find that $R^\op$ is semisimple by Artin--Wedderburn.
\end{proof}


\begin{corollary}
  Let $A$ be a finite-dimensional semisimple $k$-algebra.
  Then $A$ has finitely many nonzero minimal left ideals (i.e.\ simple $A$-submodules) $I_1, \dotsc, I_r$ (up to isomorphism of left ideal) and
  \[
    A \cong \Mat_{n_1}(D_1) \times \dotsm \times \Mat_{n_r}(D_r)
  \]
  where $D_i = \End_A(I_i)^\op$.
\end{corollary}
\begin{proof}
  We will prove this later.
\end{proof}


\begin{corollary}\label{corollary: semisimple algebra product of matrix algebras over field}
  Let $k$ be an algebraically closed field and $A$ a finite-dimensional semisimple $k$-algebra.
  Then
  \[
    A \cong \Mat_{n_1}(k) \times \dotsm \times \Mat_{n_r}(k)
  \]
  as $k$-algebras for some $r \geq 1$ and $n_1, \dotsc, n_r \geq 1$.
\end{corollary}
\begin{proof}
  Using Artin--Wedderburn we find that we have an isomorphism of rings
  \[
    A \cong \Mat_{n_1}(D_1) \times \dotsm \times \Mat_{n_r}(D_r)
  \]
  for some $r \geq 1$, $n_1, \dotsc, n_r \geq 1$ and skew fields $D_1, \dotsc, D_r$ where
  \[
    D_i = \End_A(S_i)^\op
  \]
  for a simple $A$-module $S_i$ for every $1 \leq i \leq r$.
  By Proposition \ref{proposition: simple modules over finite-dimensional algebras} $\dim_k S_i < \infty$ and thus by Schur’s Lemma $D_i = k$ for every $1 \leq i \leq r$.
\end{proof}


\begin{proof}[Proof of Artin--Wedderburn]
  We start by showing the existance:
  By Lemma \ref{lemma: semisimple ring with 1 only finitely many summands} we have $R = \bigoplus_{i = 1}^n L_i$ as $R$-modules for some $n \geq 1$ and simple submodules $L_i \subseteq R$.
  By sorting these submoduls by isomorphism classes we get
  \[
    R \cong n_1 V_1 \oplus \dotsb \oplus n_r V_r
  \]
  for $n_1, \dotsc, n_r \geq 1$ and pairwise non-isomorphic simple $R$-modules $V_1, \dotsc, V_r$.
  Since it is enough to prove the theorem for $n_1 V_1 \oplus \dotsb \oplus n_r V_r$ we will assume that $R = n_1 V_1 \oplus \dotsb \oplus n_r V_r$.
  
  By Schur’s Lemma we find for every $1 \leq i \leq r$
  \[
          \End_R(n_i V_i)
    \cong \Mat_{n_i}(\End_R(V_i))
  \]
  where $\End_R(V_i)$ is a skew field, and
  \[
          \End_R(n_1 V_1 \oplus \dotsb \oplus n_r V_r)
    \cong \End_R(n_1 V_1) \oplus \dotsb \oplus \End_R(n_r V_r)
  \]
  because the $V_i$ are pairwise non-isomorpic.
  Using Lemma \ref{lemma: End_R(R) = Rop} we find that
  \begin{align*}
            R^\op
    &\cong  \End_R(R) \\
    &\cong  \End_R(n_1 V_1 \oplus \dotsb \oplus n_r V_r) \\
    &\cong  \End_R(n_1 V_1) \times \dotsb \times \End_R(n_r V_r) \\
    &\cong  \Mat_{n_1}(D_1) \times \dotsb \times \Mat_{n_r}(D_r)
  \end{align*}
  as rings for the skew field $D_i \coloneqq \End_R(V_i)$.
  Therefore
  \begin{align*}
            R
    &\cong  \left( R^\op \right)^\op \\
    &\cong  \left( \Mat_{n_1}(D_1) \times \dotsb \times \Mat_{n_r}(D_r) \right)^\op \\
    &=      \Mat_{n_1}(D_1)^\op \times \dotsb \times \Mat_{n_r}(D_r)^\op \\
    &\cong  \Mat_{n_1}\left( D_1^\op \right) \times \dotsb \times \Mat_{n_r}\left( D_r^\op \right)
  \end{align*}
  as rings where $D_i^\op$ is a skew field for every $1 \leq i \leq r$.
  
  To see the uniquness let
  \begin{align}
            R
    &\cong  \Mat_{n_1}(D_1) \times \dotsm \times \Mat_{n_r}(D_r) \,,
    \label{eqn: artin wedderburn isomorphisms 1}
  \shortintertext{and}
            R
    &\cong \Mat_{n'_1}(D'_1) \times \dotsm \times \Mat_{n'_s}(D'_s)
    \label{eqn: artin wedderburn isomorphisms 2} 
  \end{align}
  for $r, s \geq 1$, $n_1, \dotsc, n_r, n'_1, \dotsc, n'_s \geq 1$ and skew fields $D_1, \dotsc, D_r$, $D'_1, \dotsc, D'_s$.
  We start by noticing that
  \[
      r
    = |\Irr(R)|
    = s \,,
  \]
  so $r$ is unique.
  Using the isomorphisms \eqref{eqn: artin wedderburn isomorphisms 1} and \eqref{eqn: artin wedderburn isomorphisms 2} of rings we can make $\Mat_{n_1}(D_1) \times \dotsm \times \Mat_{n_r}(D_r)$ and $\Mat_{n'_1}(D'_1) \times \dotsm \times \Mat_{n'_r}(D'_r)$ into $R$-modules, such that \eqref{eqn: artin wedderburn isomorphisms 1} and \eqref{eqn: artin wedderburn isomorphisms 2} are also isomorphisms of $R$-modules.
  By decomposing $\Mat_{n_i}(D_i)$ into simple $R$-submodules (which are the same as simple $\Mat_{n_i}(D_i)$ submodules) $\Mat_{n_i}(D_i) = C^i_1 \oplus \dotsb \oplus C^i_{n_i}$ in the usual way (so $C^i_j$ are the matrices in $\Mat_{n_i}(D_i)$ for which all but the $j$-the column are zero and $C^i_j \cong D_i^{n_i}$) we get a decomposition
  \[
      \Mat_{n_1}(D_1) \times \dotsm \times \Mat_{n_r}(D_r)
    = \bigoplus_{i=1}^r \bigoplus_{j=1}^{n_i} C^i_j
  \]
  into simple $R$-submodules.
  In the same way we get a decomposition
  \[
      \Mat_{n'_1}(D'_1) \times \dotsm \times \Mat_{n'_r}(D'_r)
    = \bigoplus_{i=1}^r \bigoplus_{j=1}^{n'_i} C'^i_j
  \]
  into simple $R$-submodules.
  We know that $C^{i_1}_{j_1} \cong C^{i_2}_{j_2}$ as $R$-modules if and only if $i_1 = i_2$, the same goes for the $C'^i_j$.
  In particular both $C^1_1, \dotsc, C^r_1$ and $C'^1_1, \dotsc, C'^r_1$ are a complete collection of representatives of $\Irr(R)$.
  Since the $R$-endomorphism rings of the $C^i_j$ and $C'^i_j$ are skew fields by Schur’s Lemma we find by the theorem of Krull-Remak-Schmidt (which we will not prove in this lecture) that there exists a bijection
  \[
            \pi
    \colon  \left\{
              C^i_j
            \,\middle|\,
              1 \leq i \leq r, 
              1 \leq j \leq n_i
            \right\}
    \to     \left\{
              C'^i_j
            \,\middle|\,
              1 \leq i \leq r,
              1 \leq j \leq n'_i
            \right\}
  \]
  such that $\pi(C^i_j) \cong C^i_j$ for every $C^i_j$.
  Since $\pi$ restricts to bijections between the isomorphism classes of the $C^i_j$ and $C'^i_j$ we find a bijection
  \[
            \tau
    \colon  \{1, \dotsc, r\}
    \to     \{1, \dotsc, r\}
  \]
  such that $\pi$ restricts to a bijection
  \[
            \pi_i
    \colon  \{ C^i_1, \dotsc, C^i_{n_i} \}
    \to     \{ C^{\tau(i)}_1, \dotsc, C^{\tau(i)}_{n'_i} \}
  \]
  for every $1 \leq i \leq r$.
  Thus we find that $n_i = n'_i$.
  Because we have $C^i_1 \cong C^{\tau(i)}_1$ for every $1 \leq i \leq r$ and
  \[
          \End_R(C^i_1)
    \cong \End_{\Mat_{n_i}(D_i)}(C^i_1)
    \cong \End_{\Mat_{n_i}(D_i)}(D^n)
    \cong D_i^\op
  \]
  as well as $\End_R(C^{\tau(i)}_1) \cong D_{\tau(i)}'^\op$ we also find that
  \[
          D_i^\op
    \cong D_{\tau(i)}'^\op
  \]
  and thus $D_i \cong D'_{\tau(i)}$.
\end{proof}





\section{Simple Rings}


\begin{definition}
  A ring $R$ is called \emph{simple} if it’s only two-sided ideals are $R$ and $0$.
\end{definition}


\begin{warn}
  This definition of a simple ring is no equivalent to the last one:
  Earlier we defined a ring $R$ to be simple if it is semisimple and has precisely one simple module up to isomorphism.
  We will refer to these rings as \emph{simple according to definition 1}.
  Rings which are simple according to the new definition above will be referred to as just \emph{simple}.
\end{warn}


\begin{expls}
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      Let $D$ be a division ring and $n \geq 1$.
      We have already seen that $\Mat_n(D)$ is a simple according to definition 1.
      It is also simple:
      Let $I \subseteq \Mat_n(D)$ be a two-sided ideal with $I \neq 0$.
      Let $A = (a_{ij})_{1 \leq i,j \leq n} \in I$ with $A \neq 0$.
      Then $a_{ij} \neq 0$ for some $1 \leq i,j \leq n$.
      Therefore
      \[
          \diag\left( a_{ij}^{-1}, \dotsc, a_{ij}^{-1} \right) E_{ii} A E_{jj}
        = E_{ij} \in I
      \]
      and thus for every $1 \leq k,l \leq n$
      \[
            E_{kl}
        =   E_{ki} E_{ij} E_{jl}
        \in I \,.
      \]
      Since $I$ is a $D$-submodule of $\Mat_n(D)$ we find that $I = \Mat_n(D)$.
    \item
      The Weyl-algebra
      \[
          \mc{A}_2
        = k \gen{X,\partial} / (X \partial - \partial X - 1)
      \]
      is simple, but not simple according to definition 1.
  \end{enumerate}
\end{expls}


\begin{warn}
  A simple ring $R$ is not necessarily simple as an $R$-module.
  A counterexample is $\Mat_n(D)$ for a skew field $D$ and $n \geq 2$.
\end{warn}


\begin{lemma}
  Let $R$ be a ring (with $1$).
  If $R$ is simple according to definition 1 it is also simple.
\end{lemma}
\begin{proof}
  Since $R$ is semisimple we have
  \[
    R \cong \Mat_{n_1}(D_1) \times \dotsb \times \Mat_{n_r}(D_r)
  \]
  for $r \geq 1$, $n_1, \dotsc, n_r \geq 1$ and skew fields $D_1, \dotsc, D_r$ by Artin--Wedderburn.
  Since $r = |\Irr(R)| = 1$ we have
  \[
    R \cong \Mat_n(D)
  \]
  for $n \geq 1$ and a skew field $D$.
\end{proof}


We can also ask ourselves under what conditions a simple ring $R$ is semisimple (and thus semisimple as an $R$-module). The following theorem by Wedderburn answers that question:


\begin{theorem}[Wedderburn]
  Let $R$ be a simple ring (with $1$). Then the following are equivalent:
  \begin{enumerate}[label=\emph{\roman*)},leftmargin=*]
    \item \label{enum: semisimple}
      $R$ is semisimple.
    \item \label{enum: left artian}
      $R$ is (left) artian.
    \item \label{enum: minimal left ideal}
      $R$ has a minimal left ideal $I \neq 0$.
    \item \label{enum: matrix ring over skew field}
      $R \cong \Mat_n(D)$ for some $n \in \N$ and skew field $D$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  The equivalence of \ref{enum: semisimple} and \ref{enum: matrix ring over skew field} follows directly from Artin--Wedderburn.
  
  To show that \ref{enum: semisimple} implies \ref{enum: left artian} suppose that \ref{enum: semisimple} holds.
  Then $R = \bigoplus_{i=1}^s V_i$ where $V_i \subseteq R$ is a simple $R$-module for every $1 \leq i \leq s$.
  Then
  \[
              0
    \subseteq V_1
    \subseteq V_1 \oplus V_2
    \subseteq \dotsb
    \subseteq V_1 \oplus \dotsb \oplus V_s
    =         R
  \]
  is a composition series of $R$, so by the Jordan-Hölder theorem (which we will not prove in this lecture) every strictly decreasing chain of left ideals in $R$ stabilizes (after at most $s$ ideal).
  
  To see that \ref{enum: left artian} implies \ref{enum: minimal left ideal} notice that if \ref{enum: minimal left ideal} does not hold we have an infinite chain
  \[
                A
    \supsetneq  I_1
    \supsetneq  I_2
    \supsetneq  I_3
    \supsetneq  \dotso
  \]
  of strictly decreasing nonzero left ideals, which contradicts \ref{enum: left artian}.
  
  Last we show that \ref{enum: minimal left ideal} implies \ref{enum: semisimple}.
  Suppose that $I \neq 0$ is a minimal left ideal.
  Then for every $r \in R$ the left ideal $Ir$ is either zero or minimal (i.e.\ simple as an $R$-submodule), since the map
  \[
            \varphi
    \colon  I
    \to     Ir,
    \quad   x
    \mapsto xr
  \]
  is an epimorphism of $R$-modules and thus either zero or an isomorphism (since $I$ is a simple $R$ module).
  Now
  \[
              J
    \coloneqq \sum_{r \in R} Ir
    =         IR
  \]
  is a two-sided ideal in $R$ which is nonzero (because $0 \subsetneq I = I1 \subseteq J$), so $J = R$.
  This show that $R$ is the sum of simple submodules.
\end{proof}


\begin{corollary}
  Let $A$ be finite-dimensional simple $k$-algebra.
  Then $A$ is semisimple and $A \cong \Mat_n(D)$ for some skew field $D$ and $n \in \N$.
\end{corollary}
\begin{proof}
  Because $A$ is finite-dimenisonal it contains a minimal ideal $I \neq 0$.
  The rest follows from Wedderburn’s theorem.
\end{proof}


\begin{lemma}
  Let $D$ be a skew field and $n \geq 1$.
  Then $Z(D)$ is a field and
  \[
    Z(\Mat_n(D)) \cong Z(D)
  \]
  as rings.
\end{lemma}
\begin{proof}
  We start by showing that $Z(D)$ is a field.
  We know that $Z(D) \subseteq D$ is a commutative subring (with $1$).
  Since $0 \neq 1$ in $D$ we also have $0 \neq 1$ in $Z(D)$.
  $Z(D)$ is also an integral domain, since $D$ is.
  All that we need to show is that for every $x \in Z(D)$ we also have $x^{-1} \in Z(D)$.
  This is clear, because for every $y \in D$
  \[
      x^{-1} y
    = x^{-1} y x x^{-1}
    = x^{-1} x y x^{-1}
    = y x^{-1} \,.
  \]
  
  Next we show that $Z(\Mat_n(D)) \cong Z(D)$.
  For this let $A \in Z(\Mat_n(D))$.
  We first show that $A$ is a diagonal matrix.
  To see this let $\pi_{ij} \colon \Mat_n(D) \to D$ be the canonical projection of the $(i,j)$-th coordinate for all $1 \leq i,j \leq n$.
  For all $1 \leq i,j \leq n$ we have
  \[
      a_{ij}
    = \pi_{ij}(E_{ii} A_{ij} E_{jj})
    = \pi_{ij}(E_{ii} E_{jj} A)
    = \delta_{ij} a_{ij} \,,
  \]
  so $a_{ij} = 0$ for $i \neq j$.
  Let $d_1, \dotsc, d_n \in D$ with $A = \diag(d_1, \dotsc, d_n)$.
  For every $1 \leq i,j \leq n$ we have
  \begin{align*}
        d_i
    &=  \pi_{ii}(A E_{ii})
     =  \pi_{ii}(A E_{ij} E_{jj} E_{ji})
     =  \pi_{ii}(E_{ij} A E_{jj} E_{ji}) \\
    &=  \pi_{ii}(E_{ij} d_j E_{jj} E_{ji})
     =  \pi_{ii}(d_j E_{ij} E_{jj} E_{ji})
     =  \pi_{ii}(d_j E_{ii})
     =  d_j \,,
  \end{align*}
  so $A = \diag(d, \dotsc, d)$ for $d \coloneqq d_1 = \dotsb = d_n$.
  Since $A$ commutes with all diagonal matrices we have $d \in Z(D)$.
\end{proof}


\begin{definition}
  Let $k$ be a field.
  A $k$-algebra $A$ is called a \emph{central simple algebra (over $k$)} if $A$ is finite-dimensional, simple and $Z(A) = k$.
\end{definition}


\begin{lemma}\label{lemma: Z(A o B) = Z(A) o Z(B)}
  Let $A$ and $B$ be $k$-algebras.
  Then
  \[
      Z(A \otimes_k B)
    = Z(A) \otimes_k Z(B) \,.
  \]
\end{lemma}


\begin{rec}
  Let $k$ be a field $V$ and $W$ be $k$-vector spaces.
  We know from linear algebra that every element $x \in V \otimes_k W$ can be written as a finite sum of simple tensors $x = \sum_{i=1}^n v_i \otimes w_i$.
  Furthermore $v_1, \dotsc, v_n$ are unique if $w_1, \dotsc, w_n \in W$ are linearly independent.
  \begin{proof}
    We can assume w.l.o.g.\ that $W = \vspan_k \{w_1, \dotsc, w_n\}$.
    We have for every $1 \leq i \leq n$ a $k$-bilinear map
    \[
              s_i
      \colon  V \times W \to V,
      \quad   \left(v, \sum_{i=1}^n \lambda_i w_i\right)
      \mapsto \lambda_i v \,.
    \]
    and thus a $k$-linear map
    \[
              f_i
      \colon  V \otimes_k W
      \to     V,
      \quad   v \otimes w_j
      \mapsto \delta_{ij} v \,.
    \]
    For $x \in V \otimes_k W$ with $x = \sum_{j=1}^n v_j \otimes w_j = \sum_{j=1}^n v'_j \otimes w_j$ we have
    \[
        0
      =   \left( \sum_{j=1}^n v_j \otimes w_j \right)
        - \left( \sum_{j=1}^n v'_j \otimes w_j \right)
      = \sum_{j=1}^n (v_j - v'_j) \otimes w_j
    \]
    and therefore for every $1 \leq i \leq n$
    \[
        v_i - v'_i
      = f_i\left( \sum_{j=1}^n (v_j - v'_j) \otimes w_j\right)
      = f_i(0)
      = 0 \,.
      \qedhere
    \]
  \end{proof}
\end{rec}


\begin{proof}[Proof of the Lemma]
  It is clear that $Z(A) \otimes_k Z(B) \subseteq Z(A \otimes_k B)$.
  To show the other inclusion let $x \in Z(A \otimes_k B)$.
  We can write $x = \sum_{i=1}^n a_i \otimes b_i$.
  We can assume w.l.o.g.\ that both $a_1, \dotsc, a_n$ and $b_1, \dotsc, b_n$ are linearly independent.
  For every $a \in A$ we have
  \[
      \sum_{i=1}^n (a a_i) \otimes b_i
    = (a \otimes 1) x
    = x (a \otimes 1)
    = \sum_{i=1}^n (a_i a) \otimes b_i
  \]
  and thus $a_i a = a a_i$ (because $b_1, \dotsc, b_n$ are linearly independent).
  So $a_i \in Z(A)$ for every $1 \leq i \leq n$.
  In the same way we find that $b_1, \dotsc, b_n \in Z(B)$.
  This shows that $x \in Z(A) \otimes_k Z(B)$.
\end{proof}


\begin{proposition}
  Let $A$ and $B$ be central simple algebras over the same field $k$.
  Then $A \otimes_k B$ is a central simple algebra.
\end{proposition}
\begin{proof}
  Since both $A$ and $B$ are finite-dimensional the same holds for $A \otimes_k B$.
  By Lemma \ref{lemma: Z(A o B) = Z(A) o Z(B)} we have
  \[
      Z(A \otimes_k B)
    = Z(A) \otimes_k Z(B
    = k \otimes_k k
    = k \,.
  \]
  So we only need to show that $A \otimes_k B$ only contains $0$ and $A \otimes_k B$ as two-sided ideals.
  To show this let $I \subseteq A \otimes_k B$ be a two-sided ideal with $I \neq 0$.
  We can write every $u \in I$ as $u = \sum_{i=1}^n a_i \otimes b_i$ where $b_1, \dotsc, b_n$ are linearly independent.
  Let $u \in I$ with $u \neq 0$ such that $u$ can be written as above so that the number of summands is minimal with respect to all nonzero elements in $I$.
  Let
  \begin{equation}\label{eqn: u as a sum}
    u = \sum_{i=1}^n a_i \otimes b_i
  \end{equation}
  be such a sum.
  Since $n$ is minimal we have $a_1 \neq 0$.
  Therefore the two-sided ideal $A a_1 A \subseteq A$ is non-zero, so $A a_1 A = A$ because $A$ is simple.
  In particular there exists $c, c' \in A$ with $1 = c a_1 c'$.
  By multiplying \eqref{eqn: u as a sum} from the left with $(c \otimes 1)$ and from the right with $(c' \otimes 1)$ we see that the element
  \[
              x
    \coloneqq (c \otimes 1) u (c' \otimes 1)
    \in       I
  \]
  can be written as
  \begin{equation}\label{eqn: x as a sum}
        x
    =   1 \otimes b_1
      + a'_2 \otimes b_2
      + \dotsb
      + a'_n \otimes b_n
  \end{equation}
  where $b_1, \dotsc, b_n$ are linearly independent.
  In particular $x \neq 0$.
  For every $a \in A$ we have
  \[
        (a \otimes 1) x - x (a \otimes 1)
    =   (a a'_2 - a'_2 a) \otimes b_2
      + \dotsb
      + (a a'_n - a'_n a) \otimes b_2 \in I \,.
  \]
  By the minimality of $u$ we find that
  \[
      (a \otimes 1) x - x (a \otimes 1)
    = 0
  \]
  for every $a \in A$.
  Because $b_2, \dotsc, b_n$ are linearly independent it follows that $a a'_i - a'_i a = 0$ for all $a \in A$ and $2 \leq i \leq n$.
  So $a'_2, \dotsc, a'_n \in Z(A) = k$.
  Using \eqref{eqn: x as a sum} we find that $x = 1 \otimes b$ for some $b \in B$.
  Since $x \neq 0$ we also have $b \neq 0$.
  Because $B$ is simple we find that $BbB = B$ and therefore
  \[
              I
    \supseteq (1 \otimes B) x (1 \otimes B)
    =         1 \otimes (BbB)
    =         1 \otimes B \,.
  \]
  Using this we find that
  \[
              I
    \supseteq (A \otimes 1) (1 \otimes B)
    =         A \otimes_k B \,.
  \]
  So $0$ and $A \otimes_k B$ are the only two-sided ideals in $A \otimes_k B$.
\end{proof}





\section{Characters and Class Functions}


\begin{definition}
  Let $A$ be a $k$-algebra, $V$ a finite-dimensional representation of $A$.
  Let
  \[
            \rho
    \colon  A
    \to     \End_k(V),
    \quad   a
    \mapsto (v \mapsto av)
  \]
  be the corresponding algebra homomorphism.
  Then the \emph{character $\chi_V \in A^*$ of $V$} is defined as
  \[
            \chi_V
    \colon  A
    \to     k,
    \quad   a
    \mapsto \tr \rho(a) \,.
  \]
\end{definition}


\begin{proposition}\label{proposition: properties characters}
  Let $A$ be a $k$-algebra.
  Let $V$ and $W$ be finite-dimensional $A$-modules and $U \subseteq V$ a submodule.
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      If $V \cong W$ (as $A$-modules) then $\chi_V = \chi_W$.
    \item
      We have $\chi_{V \oplus W} = \chi_V + \chi_W$.
    \item
      We have $\chi_V = \chi_U + \chi_{V/U}$.
    \item
      We have $\chi_{V \otimes W} = \chi_V \cdot \chi_W$.
  \end{enumerate}
  Suppose that $A = kG$ for some group $G$ and let $g,h \in G$.
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*,resume]
    \item
      We have $\chi_V(e) = \dim_k V \bmod \kchar k$.
    \item
      We have $\chi_V(hgh^{-1}) = \chi_V(g)$.
    \item
      When taking $V^*$ as a representation of $G$ in the usual way we have $\chi_{V^*}(g) = \chi_V(g^{-1})$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  Let $v_1, \dotsc, v_r$ be a $k$-basis of $U$, $v_1, \dotsc, v_r$, $v_{r+1}, \dotsc, v_s$ a $k$-basis of $V$ and $w_1, \dotsc, w_t$ a $k$-basis of $W$.
  For every occuring module $X$ of $A$ let
  \[
            \rho_X
    \colon  A
    \to     \End_k(X),
    \quad   a
    \mapsto (x \mapsto ax) \,.
  \]
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      Let $\varphi \colon V \to W$ be an isomorphism of $A$-modules.
      Since $A$ is unary $\varphi$ is $k$-linear.
      Therefore $\varphi(v_1), \dotsc, \varphi(v_s)$ is a $k$-basis of $W$.
      Let $a \in A$.
      If $M \in \Mat_r(k)$ is the representing matrix of $\rho_V(a)$ with respect to the basis $v_1, \dotsc, v_s$ it is also the representing matrix of $\rho_W(a)$ with respect to the basis $\varphi(v_1), \dotsc, \varphi(v_s)$.
      Therefore
      \[
          \chi_V(a)
        = \tr \rho_V(a)
        = \tr M
        = \tr \rho_W(a)
        = \chi_W(a) \,.
      \]
    \item
      Let $a \in A$.
      If $M_1 \in \Mat_s(k)$ is the representing matrix of $\rho_V(a)$ with respect to the basis $v_1, \dotsc, v_s$ and $M_2 \in \Mat_t(k)$ the representing matrix of $\rho_W(a)$ with respect to the basis $w_1, \dotsc, w_t$, then
      \[
                  M
        \coloneqq \begin{pmatrix}
                    M_1 & 0 \\
                    0 & M_2
                  \end{pmatrix}
      \]
      is the representing matrix of $\rho_{V \oplus W}(a)$ with respect to the basis $v_1, \dotsc, v_s$, $w_1, \dotsc, w_t$.
      Therefore
      \begin{align*}
            \chi_{V \oplus W}(a)
        &=  \tr \rho_{V \oplus W}(a)
         =  \tr M
         =  \tr M_1 + \tr M_2 \\
        &=  \tr \rho_V(a) + \tr \rho_W(a)
         =  \chi_V(a) + \chi_W(a) \,.
      \end{align*}
    \item
      Let $a \in A$.
      Let $M_1 \in \Mat_r(k)$ be the representing basis of $\rho_U(a)$ with respect to $v_1, \dotsc, v_r$ and $M_2 \in \Mat_{s-r}$ be the representing matrix of $\rho_{V/U}(a)$ with respect to the basis $v_{r+1} + U, \dotsc, v_s + U$.
      Then
      \[
                  M
        \coloneqq \begin{pmatrix}
                    M_1 & 0 \\
                    0 & M_2
                  \end{pmatrix}
      \]
      is the representing matrix of $\rho_V(a)$ with respect to the basis $v_1, \dotsc, v_r$, $v_{r+1}, \dotsc, v_s$ of $V$.
      Therefore
      \begin{align*}
            \chi_V(a)
        &=  \tr \rho_V(a)
         =  \tr M
         =  \tr M_1 + \tr M_2 \\
        &=  \tr \rho_U(a) + \tr \rho_{V/U}(a)
         =  \chi_U(a) + \chi_{V/U}(a).
      \end{align*}
    \item
      Let $a \in A$.
      Let $M \in \Mat_s(k) = (m_{ij})_{1 \leq i,j \leq s}$ be the representing matrix of $\rho_V(a)$ with respect to the basis $v_1, \dotsc, v_s$ and $N$ the representing matrix of $\rho_W(a)$ with respect to the basis $w_1, \dotsc, w_t$.
      Since
      \[
          \rho_{V \otimes W}(a)
        = \rho_V(a) \otimes \rho_W(a)
      \]
      the representing matrix of $\rho_{V \otimes W}(a)$ with respect to the basis $v_1 \otimes w_1$, $v_1 \otimes w_2, \dotsc, v_r \otimes w_t$ is
      \[
          M \otimes N
        = \begin{pmatrix}
            m_{11} N & m_{12} N & \cdots & m_{1s} N \\
            m_{21} N & m_{22} N & \cdots & m_{2s} N \\
            \vdots   & \vdots   & \ddots & \vdots   \\
            m_{s1} N & m_{s2} N & \cdots & m_{ss} N
          \end{pmatrix}.
      \]
      Therefore
      \begin{align*}
            \chi_{V \otimes W}(a)
        &=  \tr \rho_{V \otimes W}(a)
         =  \tr M \otimes N
         =  \tr M \cdot \tr N \\
        &=  \tr \rho_V(a) \cdot \tr \rho_W(a)
         =  \chi_V(a) \cdot \chi_W(a) \,.
      \end{align*}
    \item
      The representing matrix of $\rho_V(e)$ (with respect to any $k$-basis of $V$) is the identity matrix $I_s \in \Mat_s(k)$.
      Therefore
      \[
          \chi_V(e)
        = \tr \rho_V(e)
        = \tr I_s
        = s \bmod \kchar k
        = \dim_k V \bmod \kchar k
      \]
    \item
      Let $M$ be the representing matrix of $\rho_V(g)$ with respect to the basis $v_1, \dotsc, v_s$ and $N$ be the representing matrix of $\rho_V(h)$ with respect to the basis $v_1, \dotsc, v_s$.
      Then $N^{-1}$ is the representing matrix of $\rho_V(h^{-1}) = \rho_V(h)^{-1}$ with respect to the basis $v_1, \dotsc, v_s$.
      Therefore
      \begin{align*}
            \chi_V\left( hgh^{-1} \right)
        &=  \tr \rho_V\left( hgh^{-1} \right)
         =  \tr\left( \rho_V(h) \rho_V(g) \rho_V\left( h^{-1} \right) \right) \\
        &=  \tr\left( NMN^{-1} \right)
         =  \tr M
         =  \tr \rho_V(g)
         =  \chi_V(g) \,.
      \end{align*}
    \item
      Let $M \in \Mat_s(k)$ be the representing matrix of $\rho_V(g)$ with respect to the basis $v_1, \dotsc, v_s$ and $M^* \in \Mat_s(k)$ be the representing matrix of $\rho_{V^*}(g)$ with respect to the basis $v_1^*, \dotsc, v_s^*$.
      Then $M^{-1}$ is the representing matrix of $\rho_V(g^{-1}) = \rho_V(g)^{-1}$ with respect to the basis $v_1, \dotsc, v_s$.
      We also know from the tutorial problems that $M^* = \left(A^{-1}\right)^T$.
      Therefore
      \begin{align*}
            \chi_{V^*}(g)
        &=  \tr \rho_{V^*}(g)
         =  \tr M^*
         =  \tr \left(M^{-1}\right)^T \\
        &=  \tr M^{-1}
         =  \tr \rho_V\left( g^{-1} \right)
         =  \chi_V\left( g^{-1} \right) \,.
        \qedhere
      \end{align*}
  \end{enumerate}
\end{proof}


\begin{lemma}
  Let $A$ be a $k$-algebra and $V$ an $A$-module.
  Then $\chi_V(a) = 0$ for every $a \in [A,A]$.
\end{lemma}
\begin{proof}
  Let $a, b \in A$.
  Then
  \begin{align*}
     &\,  \chi_V(ab - ba)
    =     \tr \rho_V(ab - ba) \\
    =&\,  \tr \left(
                \rho_V(a) \rho_V(b) - \rho_V(b) \rho_V(a)
              \right) \\
    =&\,  \tr(\rho_V(a)\rho_V(b)) - \tr(\rho_V(b)\rho_V(a)) \\
    =&\,  \tr(\rho_V(a)\rho_V(b)) - \tr(\rho_V(a)\rho_V(b)) \\
    =&\,  0 \,.
  \end{align*}
  Since $[A,A]$ is generated by the elements $ab - ba$ as a $k$-vector space and $\chi_V$ is $k$-linear we have $\chi_V(a) = 0$ for all $a \in [A,A]$.
\end{proof}


With this Lemma we find that for every $k$-Algebra $A$ and $A$-module $V$ the character $\chi_V$ factors through $A/[A,A]$ a $k$-linear map.
Because of this we will regard $\chi_V$ as an element $\chi_V \in (A/[A,A])^*$


\begin{theorem} \label{theorem: characters as a basis}
  Let $k$ be an algebraically closed field and $A$ a $k$-algebra.
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      Let $V_i$, $i \in I$ be pairwise non-isomorphic simple $A$-modules.
      Then $\chi_i$, $i \in I$ are linearly independent (over $k$).
    \item
      If $A$ is finite-dimensional and semisimple we know from Proposition \ref{proposition: simple modules over finite-dimensional algebras} that $\irr(A) = \Irr(A)$.
      Then the characters $\chi_{V_i}$, $[V_i] \in \Irr(A)$ form a $k$-basis of $(A/[A,A])^*$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      Let $V_1, \dotsc, V_r$ be pairwise non-isomorphic simple $A$-modules and $\lambda_1, \dotsc, \lambda_r \in k$ with
      \[
          \sum_{i=1}^r \lambda_i \chi_{V_i}
        = 0 \,.
      \]
      For all $1 \leq i \leq r$ let
      \[
                \rho_i
        \colon  A
        \to     \End_k(V_i),
        \quad   a
        \mapsto (v \mapsto av).
      \]
      For every $a \in A$ we have
      \[
          0
        = \left( \sum_{i=1}^r \lambda_i \chi_{V_i} \right)(a)
        = \sum_{i=1}^r \lambda_i \chi_{V_i}(a)
        = \sum_{i=1}^r \lambda_i \tr \rho_{V_i}(a) \,.
      \]
      Fix $1 \leq j \leq r$.
      For every $1 \leq i \leq r$ there exists $\varphi_i \in \End_k(V_i)$ with $\tr \varphi_i = \delta_{ij}$.
      By the Lemma \ref{lemma: map into sum endomorphisms surjective} the map
      \[
                \bigoplus_{i=1}^r \rho_{V_i}
        \colon  A
        \to     \bigoplus_{i=1}^r \End_k(V_i)
      \]
      is surjective.
      Therefore there exists $b \in A$ such that $\rho_{V_i}(b) = \varphi_i$ for all $1 \leq i \leq r$.
      Thus we have
      \[
          0
        = \sum_{i=1}^r \lambda_i \tr \rho_{V_i}(b)
        = \sum_{i=1}^r \lambda_i \tr \varphi_i
        = \sum_{i=1}^r \lambda_i \delta_{ij}
        = \lambda_j \,.
      \]
      Because $j$ is arbitrary we find that $\lambda_j = 0$ for all $1 \leq j \leq r$.
    \item
      $A$ is of the form 
      \[
        A \cong \Mat_{n_1}(k) \oplus \dotsb \oplus \Mat_{n_r}(k)
      \]
      for $r \geq 1$ and $n_1, \dotsc, n_r \geq 1$.
      (This is a corollary from the Theorem of Artin--Wedderburn, both of which we will prove in the near future.) Therefore
      \[
        [A,A] \cong \Sl_{n_1}(k) \oplus \dotsb \oplus \Sl_{n_r}(k)
      \]
      by Corollary \ref{corollary: commutator product of matrix algebras}.
      Since $\dim_k \Sl_m(k) = m^2 - 1$ for every $m \geq 1$ we find that
      \begin{align*}
         &\,  \dim_k (A/[A,A])^*
        =     \dim_k A/[A,A] \\
        =&\,  \dim_k\left(
                              \Mat_{n_1}(k) / \Sl_{n_1}(k)
                      \oplus  \dotsb
                      \oplus  \Mat_{n_r}(k) / \Sl_{n_r}(k)
                    \right) \\
        =&\,  r \,.
      \end{align*}
      From Corollary \ref{corollary: simple modules over product of matrix algebras} we find that $A$ has up to isomorphism exactly $r$ simple modules.
      Since the charactors of these are linearly independent we find that they are a $k$-basis of $(A/[A,A])^*$.
    \qedhere
  \end{enumerate}
\end{proof}


\begin{corollary}\label{corollary: number of irreducible representations of finite abelian group}
  Let $k$ be an algebraically closed field and $G$ a finite, abelian group with $\kchar k \nmid |G|$.
  Then $G$ has up to isomorphism exactly $|G|$ irreducible representations.
\end{corollary}
\begin{proof}
  The group algebra $kG$ is finite-dimensional and by Maschke’s Theorem also semisimple.
  Therefore
  \[
      |\Irr_k(G)|
    = |\Irr(kG)|
    = \dim_k (kG/[kG, kG])^*
    = \dim_k kG/[kG, kG] \,.
  \]
  Since $G$ is abelian the group algebra $kG$ is commutative, so $[kG,kG] = 0$ and
  \[
      \dim_k kG/[kG, kG]
    = \dim_k kG
    = |G| \,.
    \qedhere
  \]
\end{proof}


\begin{definition}
  Let $G$ be a group and $X$ a set.
  A function $f \colon G \to X$ is called a \emph{class function (with values in $X$)} if it is constant on the conjugation classes of $G$, i.e.\ if $f$ is invariant under conjugation.
  If we see $X$ as a trivial $G$-set then the set of $X$-valued class functions is precisely $\Maps(G,X)^G$ where $G$ acts on itself by conjugation.
\end{definition}


\begin{lemma} \label{lemma: characterisation class functions}
  Let $G$ be a group and $k$ a field (not necessarily algebraically closed).
  Let $f \colon G \to k$ be a map and $F \colon kG \to k$ the corresponding $k$-linear extension.
  Then the following are equivalent:
  \begin{enumerate}[label=\emph{\roman*)}, leftmargin=*]
    \item \label{enum: class function}
      $f$ is a class function.
    \item
      $f(gh) = f(hg)$ for all $g \in G$, $h \in H$.
    \item
      $F(ab) = F(ba)$ for all $a, b \in kG$.
    \item
      The restriction $F_{|[kG,kG]}$ is the zero map.
  \end{enumerate}
  If $G$ is additionally finite we also have the following:
  \begin{enumerate}[label=\emph{\roman*)}, leftmargin=*, resume]
    \item \label{enum: center of group algebra}
      If we see $f$ as an element of $kG$, i.e.\ $f = \sum_{g \in G} f(g) g$, then $f \in Z(kG)$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  The equivalence of the first four are easy to see.
  To see the equivalence of \ref{enum: class function} and \ref{enum: center of group algebra} notice that $f \in Z(kG)$ if and only if $hfh^{-1} = f$ for every $h \in G$.
  Since we have
    \[
        h f h^{-1}
      = h\left( \sum_{g \in G} f(g) g \right) h^{-1}
      = \sum_{g \in G} f(g) hgh^{-1}
      = \sum_{g \in G} f(h^{-1} g h) g
    \]
    this is equivalent to $f(h^{-1} g h) = f(g)$ for all $g, h \in G$.
\end{proof}


\begin{definition}
  Let $G$ be a group and $V$ a finite-dimensional representation of $G$ over a field $k$. If $\rho \colon G \to \GL(V)$ is the corresponding group homomorphism the \emph{character} of the representation $V$ is defined as the map $\chi_V \colon G \to k$ with $\chi_V(g) \coloneqq \tr \rho(g)$. It is equivalently the restriction of the character $\chi_V$ of $V$ as a $kG$-module to $G$.
\end{definition}


From Lemma \ref{lemma: characterisation class functions} we know that the character $\chi_V$ of a representation $V$ of a group $G$ over a field $k$ is a class function from $G$ to $k$.


\begin{proposition} \label{proposition: conjugation classes and irreducible representations}
  Let $G$ be a finite group and $k$ an algebraically closed field with $\kchar k \nmid |G|$.
  \begin{enumerate}[label=\emph{\alph*)}, leftmargin=*]
    \item
      Then the characters of the irreducible representations of $G$ form a $k$-basis of the $k$-vector space of class functions from $G$ to $k$.
    \item
      The number of irreducible representations of $G$ is exactly the number conjugation classes of $G$.
    \item
      The number of irreducible representations of $G$ is exactly $\dim_k Z(kG)$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  \begin{enumerate}[label=\emph{\alph*)}, leftmargin=*]
    \item
      By Lemma \ref{lemma: characterisation class functions} we can regard the $k$-vector space of class functions from $G$ to $k$ as $(kG/[kG,kG])^*$.
      Thus the statement follows directly from Theorem \ref{theorem: characters as a basis} since $kG$ is semisimple by Maschke’s theorem.
    \item
      Let $\mc{O}_1, \dotsc, \mc{O}_n$ be the conjugation classes of $G$.
      Then the characteristic functions $\chi_{\mc{O}_1}, \dotsc, \chi_{\mc{O}_n}$ form a $k$-basis of the $k$-valued class functions of $G$.
      By identifying the $k$-vector space of $k$-valued class functions of $G$ with $kG/[kG,kG]$ the same holds for the characters of irreducible representations of $G$ by the first part.
      Therefore $G$ has precisely $n$ irreducible representations.
    \item
      This follows directly from Lemma \ref{lemma: characterisation class functions} and the previous parts.
  \end{enumerate}
\end{proof}


\begin{expls}
  \begin{enumerate}[label=\emph{\alph*)}, leftmargin=*]
    \item
      Corollary is also \ref{corollary: number of irreducible representations of finite abelian group} a direct corollary of \ref{proposition: conjugation classes and irreducible representations}.
    \item
      The conjugation class of the symmetric group $S_n$ correspond directly to the partitions of $n$ in the following way:
      We can write every permutation $\pi \in S_n$ as a product of cycles
      \[
          \pi
        =         \left( x^1_1 \; \dots \; x^1_{n_1} \right)
          \dotsm  \left(x^s_1 \; \dots \; x^s_{n_s} \right),
      \]
      which is unique up to permutation of the cycles. For every $\sigma \in S_n$ we have
      \[
          \sigma \pi \sigma^{-1}
        =         \left(
                        \sigma\left( x^1_1 \right)
                    \;  \dotso
                    \;  \sigma\left( x^1_{n_1} \right)
                  \right)
          \dotsm  \left(
                        \sigma\left( x^s_1 \right)
                    \;  \dotso
                    \;  \sigma\left( x^s_{n_s} \right)
                  \right)
      \]
      So for every $m \geq 1$ the number of cycles in $\pi$ of length $m$ is invariant under conjugation.
      This is the \emph{cycle type of $\pi$}.
      
      \begin{claim}
        Two permutations are conjugated if and only if they have the same cycle type.
      \end{claim}
      \begin{proof}
        We have already seen that conjugated permutations have the same cycle type.
        On the other hand let $\pi \in S_n$ and denote by $l_m$ the number of cycles of length $m$ in $\pi$ and by $M$ the maximal length of a cycle in $\pi$.
        Then $\pi$ is conjugated to the permutation
        \[
                  \underbrace{ (1 \; \dots \; M) \dotsm ((l_M-1)M+1 \; \dots \; l_M M) }_{ \text{$l_M$ many} }
          \dotsm  \underbrace{ (n-l_1+1) \dotsm (n) }_{ \text{$l_1$ many} } \,.
        \]
        Since this permutation depends only on the cycle type of $\pi$ the statement follows.
      \end{proof}
      
      Using this we find that the permutations
      \[
                (1 \; \dotso \; \lambda_1)
                (\lambda_1 + 1 \; \dotso \; \lambda_1 + \lambda_2)
        \dotsm  (n-\lambda_s \; \dots \; n)
      \]
      for the partitions $\lambda = (\lambda_1, \dotsc, \lambda_s) \in \Par(n)$ are a set of representatives of the permutations classes of $S_n$.
      
      So we find that the number of irreducible representations of $S_n$ over an algebraically closed field $k$ with $\kchar k \nmid |S_n|$, i.e.\ $\kchar k = 0$ or $\kchar k > n$, is precisely the number of partitions of $n$.
  \end{enumerate}
\end{expls}



\begin{proposition}
  Let $A$ be a finite-dimensional $k$-algebra.
  Then the following are equivalent:
  \begin{enumerate}[label=\emph{\roman*)},leftmargin=*]
    \item \label{enum: nondegenerate symmetric associative bilinear form}
      There exists a nondegenerate symmetric bilinear form $(-,-) \colon A \times A \to k$ which is associative (i.e.\ $(ab,c) = (a,bc)$ for all $a,b,c \in A$.)
    \item \label{enum: nondegenerato linear map}
      There exists a $k$-linear map $\varepsilon \colon A \to k$ satisfying the following properties:
      \begin{enumerate}[label=\emph{(\roman*)},leftmargin=*]
        \item
          $\varepsilon(ab) = \varepsilon(ba)$ for all $a,b \in A$.
        \item
          For any $a \in A$ with $a \neq 0$ there exists $b \in B$ such that $\varepsilon(ba) \neq 0$.
      \end{enumerate}
    \item \label{enum: no nonzero ideals in kernel of linear map}
      There exists a $k$-linear map $\lambda \colon A \to k$ satisfying the following properties:
      \begin{enumerate}[label=\emph{(\roman*)},leftmargin=*]
        \item
          $\lambda(ab) = \lambda(ba)$ for all $a,b \in A$.
        \item
          $\ker \lambda$ does not contain any nonzero left-ideals of $A$.
      \end{enumerate}
  \end{enumerate}
\end{proposition}
\begin{proof}
  We first show the equivalence of \ref{enum: nondegenerato linear map} and \ref{enum: no nonzero ideals in kernel of linear map}.
  For this let $\varepsilon \colon A \to k$ be a $k$-linear map such that $\varepsilon(ab) = \varepsilon(ba)$ for all $a,b \in A$.
  That $\ker \varepsilon$ contains no nonzero left-ideals of $A$ is equivalent to saying that it does not contain any non-zero principal left-ideals of $A$.
  This is equivalent to saying that for every $a \in A$ with $a \neq 0$ we have $Aa \subsetneq \ker \varepsilon$, which is the same as saying that for every $a \in A$ with $a \neq 0$ there exists $b \in A$ with $\varepsilon(ba) \neq 0$.
  
  Next we show the equivalence of \ref{enum: nondegenerate symmetric associative bilinear form} and \ref{enum: nondegenerato linear map}.
  If \ref{enum: nondegenerate symmetric associative bilinear form} holds then \ref{enum: nondegenerato linear map} follows by setting $\varepsilon = (1,-)$.
  If \ref{enum: nondegenerato linear map} holds then \ref{enum: nondegenerate symmetric associative bilinear form} follows by defining
  \[
              (a,b)
    \coloneqq \varepsilon(ab)
    \text{ for all }
    a, b \in A \,.
    \qedhere
  \]
\end{proof}


\begin{rem}
  Since the bilinear form in \ref{enum: nondegenerate symmetric associative bilinear form} is symmetric one can also show \ref{enum: nondegenerato linear map} with $\varepsilon(ab) \neq 0$ instead of $\varepsilon(ba) \neq 0$ as well as \ref{enum: no nonzero ideals in kernel of linear map} for right-ideals instead of left-ideals.
\end{rem}


\begin{definition}
  A finite-dimensional $k$-Algebra satisfying one (and thus all) of the above conditions is called a \emph{(symmetric) Frobenius algebra}.
  A \emph{Frobenius form of $A$} refers either to a $k$-bilinear map $A \times A \to k$ satisfying \ref{enum: nondegenerate symmetric associative bilinear form} or a $k$-linear map $A \to k$ satisfying \ref{enum: nondegenerato linear map} (and thus also \ref{enum: no nonzero ideals in kernel of linear map}), depending on the situation.
\end{definition}


\begin{rem}
  For a Frobenius algebra $A$ with a Frobenius form $(-,-) \colon A \times A \to k$.
  Because $(-,-)$ is nondegenerate the $k$-linear map
  \[
            \phi
    \colon  A
    \to     A^*,
    \quad   a
    \mapsto (a,-)
  \]
  is injective.
  Because $A$ is finite-dimensional $\phi$ is an isomorphism of $k$-vector spaces.
\end{rem}


\begin{expls}
  \begin{enumerate}[label=\emph{\alph*)},leftmargin=*]
    \item
      Let $G$ be a finite-group and $k$ a field.
      Then $kG$ is a Frobenius algebra.
      To see this let the $k$-linear map $\varepsilon \colon kG \to k$ be defined as
      \[
          \varepsilon(g)
        = \begin{cases}
            1 & \text{if } g = e \,,  \\
            0 & \text{otherwise}
          \end{cases}
      \]
      for every $g \in G$, i.e.\ $\varepsilon = e^*$ with respect to the basis $G$.
      For all $a, b \in kG$ with $a = \sum_{g \in G} \lambda_g g$ and $b = \sum_{g \in G} \mu_g g$ we have
      \[
          \varepsilon(ab)
        = \sum_{g \in G} \lambda_g \mu_{g^{-1}}
        = \sum_{h \in G} \mu_h \lambda_{h^{-1}}
        = \varepsilon(ba) \,.
      \]
      For a left-ideal $I \subseteq \ker \varepsilon$ and $a \in I $ with $a = \sum_{g \in G} \lambda_g g$ we have for every $h \in G$
      \[
          \lambda_h
        = \varepsilon\left( h^{-1} a \right)
        = 0
      \]
      because $h^{-1} a \in I \subseteq \ker \varepsilon$.
      Therefore $I = 0$, which shows that $\varepsilon$ is a Frobenius form.
      
      That the corresponding bilinear form $(-,-) \colon kG \times kG \to k$, i.e.\
      \[
          (a,b)
        = \varepsilon(ab)
        \text{ for all }
        a, b \in A \,,
      \]
      is nondegenerate can also be seen by noticing that $(g^{-1},-) = g^*$ with respect to the basis $G$ for every $g \in G$.
      Therefore the $k$-linear map $kG \to kG^*$, $a \mapsto (a,-)$ is an isomorphism and in particular injective.
    \item
      Let $k$ be a field and $n \geq 1$.
      Then $\Mat_n(k)$ is the Frobenius algebra.
      To see this notice that $\tr \colon \Mat_n(k) \to k$ is a Frobenius form:
      It it clear that the corresponding bilinear form $(-,-) \colon \Mat_n(k) \times \Mat_n(k) \to k$, i.e.\
      \[
          (A,B)
        = \tr(AB)
        \text{ for all }
        A, B \in \Mat_n(k) \,,
      \]
      is symmetric and associative.
      To see that it is nondegenerate notice that $(E_{ij}, -) = E_{ji}^*$ with respect to the basis $(E_{ij})_{1 \leq i,j \leq n}$ for every $1 \leq i,j \leq n$.
      Thus the map $\Mat_n(k) \to \Mat_n(k)^*$, $A \mapsto (A,-)$ is an isomorphism and in particular injective.
  \end{enumerate}
\end{expls}


\begin{proposition}
  Let $A$ be a Frobenius algebra and $(-,-) \colon A \times A \to k$ a Frobenius form of $A$. Then
  \[
            \psi
    \colon  Z(A)
    \to     (A/[A,A])^*,
    \quad   a
    \mapsto (a,-)
  \]
  is an isomorphism of $k$-vector spaces.
\end{proposition}
\begin{proof}
  The map
  \[
            \varphi
    \colon  A
    \to     A^*,
    \quad   a
    \mapsto (a, -)
  \]
  is an isomorphism of $k$-vector spaces.
  To prove the proposition we show that $\varphi(z)_{|[A,A]} = 0$ if and only if $z \in Z(A)$.
  
  For all $z, a, b \in A$ we have
  \[
      (z,ba)
    = (1,zba)
    = (zba,1)
    = (zb,a)
    = (a,zb)
    = (az,b)
  \]
  and therefore
  \begin{align*}
        \varphi(z)(ab-ba)
    &=  (z,ab-ba)
     =  (z,ab) - (z,ba) \\
    &=  (za,b) - (az,b)
     =  (za-az,b)
     =  ([z,a],b)
  \end{align*}
  Fix $z \in A$.
  That $\varphi(z)_{|[A,A]} = 0$ is equivalent to $\varphi(z)(ab-ba) = 0$ for all $a,b \in A$.
  By the observation above this is equivalent to $([z,a],b) = 0$ for every $a,b \in A$.
  Because $(-,-)$ is nondegenerate this is equivalent to saying that $[z,a] = 0$ for every $a \in A$.
  So $\varphi(z)_{|[A,A]} = 0$ if and only if $z \in Z(A)$.
\end{proof}





\section{Double Centralizer Theorem \& Schur--Weyl Duality}


\begin{definition}
  For a field $k$ and a group $G$ we set
  \[
              \Irr_k(G)
    \coloneqq \{ \text{isomorphism classes of representations of $G$} \}
  \]
  and
  \begin{align*}
                \irr_k(G)
    &\coloneqq  \{ \text{isomorphism classes of finite-dimensional representations of $G$} \} \\
    &=          \{ [V] \in \Irr_k(G) \mid \dim_k V < \infty \}.
  \end{align*}
\end{definition}


Too see that $\Irr_k(G)$ is a set notice that irreducible representations of $G$ are the same as simple $kG$-modules and thus $\Irr_k(G) = \Irr(kG)$ for the group algebra $kG$ of $G$ over $k$.


\begin{definition}
  Let $k$ be a field, $V$ a representation of a group $G$ and $W$ a representation of a group $H$.
  Then we define the representations $V \boxtimes_k W$ of $G \times H$ as the $k$-vector space $V \otimes_k W$ together with the (linear) group action
  \[
      (g,h).(v \otimes w)
    = (g.v) \otimes (h.w) \,.
  \]
\end{definition}


To see that $V \boxtimes_k W$ is well-defined notice that the multiplication with $(g,h) \in G \times H$ is given by $\pi_g \otimes \tau_h$ where $\pi_g \colon V \to V$, $v \mapsto g.v$ is the multiplication with $g$ and $\tau_h \colon W \to W, w \mapsto h.w$ is the multiplication with $h$.


\begin{theorem}
  Let $k$ be an algebraically closed field, $G$ and $H$ groups.
  Then we have a bijection
  \[
            \Psi
    \colon  \irr_k(G) \times \irr_k(H)
    \to     \irr_k(G \times H),
    \quad   ([V],[W])
    \mapsto [V \boxtimes_k W] \,.
  \]
\end{theorem}
\begin{proof}
  We start by showing that $\Psi$ is well-defined.
  We first show that $\Psi$ is independent of the choice of representatives:
  Let $V$ and $V'$ be irreducible finite-dimensional representations of $G$ with $\phi_V \colon V \cong V'$ (as representations) and $W$ and $W'$ irreducible finite-dimenisonal representations of $H$ with $\phi_W \colon W \cong W'$.
  Then
  \[
            \phi_V \otimes \phi_W
    \colon  V  \otimes_k W
    \cong   V' \otimes_k W'
  \]
  as $k$-vector spaces.
  That $\phi_V \otimes \phi_W$ is also $(G \times H)$-equivariant can be seen by calculation since for all $(g,h) \in G \times H$ and simple tensors $v \otimes w \in V \otimes_k W$
  \begin{align*}
     &\, (\phi_V \otimes \phi_W)((g,h).(v \otimes w))
    =    (\phi_V \otimes \phi_W)((g.v) \otimes (h.w)) \\
    =&\, (\phi_V(g.v)) \otimes (\phi_W(h.w))
    =    (g.\phi_V(v)) \otimes (h.\phi_W(w)) \\
    =&\, (g,h).(\phi_V(v) \otimes \phi_W(w))
    =    (g,h).((\phi_V \otimes \phi_W)(v \otimes w)) \,.
  \end{align*}
  Since these simple tensors generate $V \otimes_k W$ as a $k$-vector space it follows that $\phi_V \otimes \phi_W$ is $(G \times H)$-equivariant.
  
  To show that $\Psi$ is well-defined we still need to show that $V \boxtimes_k W$ is irreducible and finite-dimensional for all $V \in \irr_k(G)$ and $W \in \irr_k(H)$.
  That $V \boxtimes_k W$ is finite-dimensional is clear, since
  \[
      \dim_k V \otimes_k W
    = \dim_k V \cdot \dim_k W
    < \infty \,.
  \]
  To show that $V \boxtimes_k W$ is irreducible as a representation of $G \times H$ for every irreducible representation $V$ of 
  $G$ and every irreducible representation $W$ of $H$ let
  \[
            \psi
    \colon  k(G \times H)
    \to     \End_k(V \otimes_k W)
  \]
  be the corresponding homomorphism of $k$-algebras.
  We also have the homomorphisms of $k$-algebras
  \begin{gather*}
            \phi_1
    \colon  kG
    \to     \End_k(V),
            a
    \mapsto (v \mapsto av)
  \shortintertext{and}
            \phi_2
    \colon  kH
    \to     \End_k(W),
    \quad   b
    \mapsto (w \mapsto bw) \,.
  \end{gather*}
  By Lemma \ref{lemma: equivalence to irreducible} these homomorphisms are surjective.
  Together with the isomorphisms of $k$-algebras
  \[
            kG \otimes_k kH
    \cong   k(G \times H),
    \quad   g \otimes h
    \mapsto (g,h)
  \]
  and
  \[
            \End_k(V) \otimes_k \End_k(W)
    \cong   \End(V \otimes_k W),
    \quad   f \otimes g
    \mapsto f \otimes g
  \]
  we get the following commutative diagram.
  \begin{center}
    \begin{tikzpicture}[node distance = 6em]
      \node (kG x kH) {$kG \otimes_k kH$};
      \node (End V x End W) [right = 6em of kG x kH] {$\End_k(V) \otimes_k \End_k(W)$};
      \node (kGH) [below = of kG x kH] {$k(G \times H)$};
      \node (End V x W) [below = of End V x End W] {$\End_k (V \otimes_k W)$};
      \draw[->] (kG x kH) to node[above] {$\phi_1 \otimes \phi_2$} (End V x End W);
      \draw[->] (kGH) to node[above] {$\psi$} (End V x W);
      \draw[double equal sign distance] (kG x kH) to node[left] {$\wr$} (kGH);
      \draw[double equal sign distance] (End V x End W) to node[left] {$\wr$} (End V x W);
    \end{tikzpicture}
  \end{center}
  Since both $\phi_1$ and $\phi_2$ are surjective $\phi_1 \otimes \phi_2$ is also surjective.
  Therefore $\psi$ is surjective.
  Since $V \otimes_k W \neq 0$ (since $V \neq 0$ and $W \neq 0$) we find by Lemma \ref{lemma: equivalence to irreducible} that $V \boxtimes_k W$ is irreducible as a representation of $G \times H$.
  
  Next we show that $\Psi$ is surjective.
  For this let $[Z] \in \irr_k(G \times H)$.
  By identifying $G$ with the subgroup $G \times 1 \subseteq G \times H$ we can view $Z$ as a representation of $G$.
  Since $Z$ is finite-dimensional and $Z \neq 0$ it contains some irreducible subrepresentation $V$ of $G$.
  We can turn $\Hom_G(V, Z)$ into a representation of $H$ via
  \[
      (h.f)(v)
    = h.f(v)
    \text{ for all }
    h \in H \,,\,
    f \in \Hom_G(V, Z) \,,\,
    v \in V \,,
  \]
  where we see $Z$ a representation of $H$ via the identification $H \cong 1 \times H \subseteq G \times H$.
  To see that $h.f$ is $G$-equivariant for all $h \in H$ and $f \in \Hom_G(V,W)$ notice that the actions of $G$ and $H$ on $Z$ commute, since for all $g \in G$, $h \in H$, $z \in Z$
  \[
      g.(h.z)
    = (g,1).((1,h).z)
    = (g,h).z
    = (1,h).((g,1).z)
    = h.(g.z) \,,
  \]
  and thus
  \[
      (h.f)(g.v)
    = h.(f(g.v))
    = h.(g.f(v))
    = g.(h.f(v))
    = g.((h.f)(v)) \,.
  \]
  Since $\Hom_G(V, Z)$ is finite-dimensional and $\Hom_G(V, Z) \neq 0$ (since the inclusion $\iota \colon V \hookrightarrow Z$ is $G$-equivariant and nonzero) it contains some irreducible subrepresentation $W$ of $H$.
  
  We want to show that $V \boxtimes_k W \cong Z$ as representations of $G \times H$.
  For this let
  \[
            \beta
    \colon  V \boxtimes_k \Hom_G(V,Z)
    \to     Z,
    \quad   (v, f)
    \mapsto f(v) \,.
  \]
  It is clear that $\beta$ is well-defined and $k$-linear.
  It is also $(G \times H)$-equivariant, since for or every $v \otimes f \in V \boxtimes_k \Hom_G(V,Z)$ and $(g,h) \in G \times H$ we have
  \begin{align*}
        \beta((g.h)(v \otimes f))
    &=  \beta((g.v) \otimes (h.f))
     =  (h.f)(g.v)
     =  h.f(g.v)) \\
    &=  h.g.f(v)
     =  (h,g).f(v)
     =  (h,g).\beta(v \otimes f)
  \end{align*}
  and these simple tensors $v \otimes f$ generate $V \boxtimes_k \Hom_G(V,Z)$ as a $k$-vector space.
  By restriction to $V \boxtimes_k W \subseteq V \boxtimes_k \Hom_G(V,Z)$ we get an homomorphism of representations of $(G \times H)$
  \[
            \gamma
    \colon  V \boxtimes_k W
    \to     Z,
    \quad   v \otimes f
    \mapsto f(v) \,.
  \]
  We claim that $\gamma$ is an isomorphism.
  Since $V \boxtimes_k W$ and $Z$ are both irreducible as representations of $G \times H$ and $k$ is algebraically closed it is enough to show $\gamma \neq 0$ by Schur’s Lemma.
  Since $W \neq 0$ there exists some $f \in W$ with $f \neq 0$.
  Since $f \neq 0$ there exists some $v \in V$ with $f(v) \neq 0$.
  Therefore we have $v \otimes f \in V \boxtimes_k W$ with
  \[
          \gamma(v \otimes f)
    =     f(v)
    \neq  0 \,,
  \]
  so $\gamma \neq 0$.
  
  Last we show that $\Psi$ is injective.
  For this let $[M], [M'] \in \irr_k(G)$ and $[N], [N'] \in \irr_k(H)$ with
  \[
            \alpha
    \colon  M  \boxtimes_k N
    \cong   M' \boxtimes_k N'
  \]
  As representations of $G$ (!) we have
  \[
          M \boxtimes_k N
    \cong \underbrace{ M \oplus \dotsb \oplus M }_{ \dim_k(N) \text{ copies} }
  \]
  and
  \[
          M' \boxtimes_k N'
    \cong \underbrace{ M' \oplus \dotsb \oplus M' }_{ \dim_k(N') \text{ copies} }\,.
  \]
  Since $\alpha$ is a $(G \times H)$-equivariant also $G$-equivariant and therefore an isomorphism of representations of $G$.
  Therefore we we have $M \cong M'$.
  In the same way we find that $N \cong N'$.
  This shows that $\Psi$ is injective.
\end{proof}


\begin{definition}
  For an abelian group $A$ and a subset $S \subseteq \End_\Z(A)$ the \emph{commutant} or \emph{centralizer} $S'$ of $S$ (in $\End_\Z(M)$) is defined as
  \[
              S'
    \coloneqq \{
                \varphi \in \End_\Z(M)
              \mid
                \varphi s = s \varphi
                \text{ for all }
                s \in S
              \} \,.
  \]
  The \emph{double commutant} or \emph{double centralizer} is defined as
  \[
    S'' \coloneqq (S')' \,.
  \]
  
  For an $R$-module $M$ and $S \subseteq \End_R(M)$ the \emph{commutant} or \emph{centralizer} of $S$ in $\End_R(M)$ is defined as
  \[
              S'_R
    \coloneqq \{
                \varphi \in \End_R(M)
              \mid
                \varphi s = s \varphi
                \text{ for all }
                s \in S
              \},
  \]
  and the \emph{double commutant} or \emph{double centralizer} of $S$ in $\End_R(M)$ is defined as
  \[
    S''_R \coloneqq (S'_R)'_R \,.
  \]
\end{definition}


\begin{rem}
  Let $A$ be an abelian group and $S, T \subseteq \End(A)$.
  \begin{enumerate}[label=\emph{\alph*}),leftmargin=*]
    \item \label{enum: commutant z module}
      We have $S' = S'_\Z$ and $S'' = S''_\Z$.
    \item
      If $\tilde{S} \subseteq \End(A)$ is the subring generated by $S$ then $\tilde{S}' = S'$.
      Thus we may assume that $S$ and $T$ are subrings when studying their commutants.
    \item \label{enum: commutant module homomorphisms}
      As $A$ is a left $\End(A)$-module in the usual way it is also an $S$-module by restriction.
      We then have $S' = \End_S(A)$.
    \item \label{enum: commutant contravariant}
      If $T \subseteq S$ then $S' \subseteq T'$.
    \item \label{enum: commutant adjoint}
      We have $S \subseteq T'$ if and only if $T \subseteq S'$, since both are equivalent to
      \[
        st = ts
        \text{ for every }
        t \in T,
        s \in S \,.
      \]
    \item
      We have $S' \subseteq S'$ and thus $S \subseteq S''$ by \ref{enum: commutant adjoint}.
    \item
      Since $S \subseteq S''$ we also have $S''' = (S'')' \subseteq S'$ by \ref{enum: commutant contravariant}.
      By \ref{enum: commutant adjoint} we also have $S' \subseteq (S')'' = S'''$.
      So together we have $S' = S'''$.
    \item
      The previous properties show that the double commutant is a closure operator:
      We have $S \subseteq S''$, if $T \subseteq S$ then $S' \subseteq T'$ and so $T'' \subseteq S''$, and $(S'')'' = (S''')' = (S')' = S''$.
      
      It is also easy to see that $S$ is its own double commutant if and only if it is the commutant of some subset of $\End(A)$:
      If $S = T'$ then $S'' = T''' = T' = S$.
      If $S = S''$ then $S = (S')'$.
    \item
      All of the above statements except for \ref{enum: commutant z module} and \ref{enum: commutant module homomorphisms} can also be made for the commutant in $\End_R(M)$ for some $R$-module $M$.
  \end{enumerate}
\end{rem}


\begin{rem}
  Let $k$ be a field and $V$ a $k$-vector space.
  Suppose that we have $k$-algebras $A$ and $B$ such that $V$ is both an $A$-module and a $B$-module and that both multiplications commute.
  Then $V$ is also an $A \otimes_k B$ module where
  \[
              (a \otimes b) \cdot v
    \coloneqq a \cdot (b \cdot v)
    =         b \cdot (a \cdot v) \,.
  \]
  for all $v \in V$ and simple tensors $a \otimes b \in A \otimes_k B$.
  
  So see that this multiplication is well-define let
  \begin{gather*}
            \Phi_A
    \colon  A
    \to     \End_k(V),
    \quad   a
    \mapsto (v \mapsto av)
  \shortintertext{and}
            \Phi_B
    \colon  B
    \to     \End_k(V),
    \quad   b
    \mapsto (v \mapsto bv)
  \end{gather*}
  be the corresponding algebra homomorphisms.
  This $k$-linear maps result in a $k$-bilinear map
  \[
            A \times B
    \to     \End_k(V),
    \quad   (a,b)
    \mapsto \Phi_A(a) \circ \Phi_B(b)
  \]
  and thus in a $k$-linear map
  \[
            \Psi
    \colon  A \otimes_k B
    \to     \End_k(V),
    \quad   a \otimes b
    \mapsto \Phi_A(a) \circ \Phi_B(b).
  \]
  For all simple tensors $a \otimes b, a' \otimes b' \in A \otimes_k B$ we have
  \begin{align*}
        \Psi((a \otimes b) (a' \otimes b'))
    &=  \Psi((aa') \otimes (bb'))
     =  \Phi_A(aa') \circ \Phi_B(bb') \\
    &=  \Phi_A(a) \circ \Phi_A(a') \circ \Phi_B(b) \circ \Phi_B(b') \\
    &=  \Phi_A(a) \circ \Phi_B(b) \circ \Phi_A(a') \circ \Phi_B(b') \\
    &=  \Psi(a \otimes b) \circ \Psi(a' \otimes b') \,,
  \end{align*}
  so $\Psi$ is multiplicative and therefore an algebra homomorphism.
\end{rem}


\begin{theorem}[Double Centralizer Theorem]
  Let $k$ be a field (not necessarily algebraically closed) and $W$ a finite-dimensional $k$-vector space.
  Let $A \subseteq \End_k(W)$ be a semisimple subalgebra.
  Let $A'$ be the commutant of $A$ in $\End_k(W)$, i.e.\
  \[
      A'
    = \{
        b \in \End_k(W)
        \mid
        a b = b a
        \text{ for every }
        a \in A
      \} \,.
  \]
  Then $A'$ is a semisimple subalgebra of $\End_k(W)$ and $A'' = A$.
  As an $(A \otimes_k A')$-module we have a decomposition
  \[
    W = W_1 \oplus \dotsb \oplus W_r
  \]
  into simple $(A \otimes_k A')$-modules.
  This is also a decomposition into the isotypical components of $A$ and of $A'$.
  Furthermore, each $W_i$ is of the form $W_i \cong V_i \otimes_{D_i} V'_i$ where $V_i$ is a simple $A$-module, $V'_i$ is a simple $A'$-module and $D_i = \End_A(V_i) \cong \End_{A'}(V'_i)$.
  The simple $A$-modules $V_1, \dotsc, V_n$ are a complete set of representatives of $\Irr(A)$ and the simple $A'$-modules $V'_1, \dotsc, V'_n$ are a complete set of representatives of $\Irr(A')$.
  In particular we have bijection between the isomorphism classes of simple $A$-modules and the isomorphism classes of simple $A'$-modules.
\end{theorem}


(The proof of the above theorem is missing in these notes.
If I remember correctly I didn’t understand the proof given in the lecture, and therefore didn’t write it down.)


\begin{expl}
Let $e_1$, $e_2$ be the standard basis of $\Complex^2$.
The usual action of $\GL_2(\Complex)$ on $\Complex^2$ induces an action of $\GL_2(\Complex)$ on $V \coloneqq \Complex^2 \otimes_\Complex \Complex^2$ with
  \[
      A.(v \otimes w)
    = (Av) \otimes (Aw)
  \]
  for all matrices $A \in \GL_2(\Complex)$ and simple tensors $v \otimes w \in V$.
  We also have an action of $S_2 = \{e, s\}$ on $V$ with
  \[
      s.(v \otimes w)
    = w \otimes v
  \]
  for every simple tensor $v \otimes w \in V$.
  It is clear that both actions commute and therefore induces an action of $\GL_2(\Complex) \times S_2$ on $V$ with
  \[
      (A,\sigma).v
    = A.\sigma.v
    = A.(\sigma.v)
    = \sigma.(A.v)
  \]
  for every $(A,\sigma) \in \GL_2(\Complex) \times S_2$ and $v \in V$.
  
  $V$ is completely reducible as a representation of $S_2$ with
  \[
                  V
    \cong         \Complex
          \oplus  \Complex
          \oplus  \Complex
          \oplus  \sgn
  \]
  where $\Complex$ is the one-dimensional trivial representation of $S_2$ and $\sgn$ the sign-representation of $S_2$.
  (Notice that these are, up to isomorphism, the only irreducible representations of $S_2$ by Corollary \ref{corollary: number of irreducible representations of finite abelian group} because $|\Irr(S_2)| = |S_2| = 2$.)
  The corresponding trivial subrepresentations of $V$ are spanned by $e_1 \otimes e_1$, $e_2 \otimes e_2$ and $e_1 \otimes e_2 + e_2 \otimes e_1$ respectively.
  The corresponding sign-subrepresentation of $V$ is spanned by $e_1 \otimes e_2 - e_2 \otimes e_1$.
  
  $V$ is also completely reducible as a representations of $\GL_2(\Complex)$:
  The usual isomorphism of $\Complex$-vector spaces
  \[
            V
    \cong   S^2\left( \Complex^2 \right)  \oplus  \Lambda^2\left( \Complex^2 \right),
    \quad   v \otimes w
    \mapsto (v \cdot w, v \wedge w)
  \]
  is clearly $\GL_2(\Complex)$-equivariant and thus an isomorphism of representations of $\GL_2(\Complex)$.
  
  \begin{claim}
    Both $S^2(\Complex^2)$ and $\Lambda^2(\Complex^2)$ are irreducible as representations of $\GL_2(\Complex)$.
  \end{claim}
  \begin{proof}[Proof of the claim]
    It is clear that $\Lambda^2(\Complex^2)$ is irreducible as it is one-dimensional.
    To show that $S^2(\Complex^2)$ is irreducible let $x \in \Lambda^2(\Complex^2)$ with $x \neq 0$ and $U \subseteq S^2(\Complex^2)$ be the subrepresentation generated by $x$.
    Since $e_1^2$, $e_1 e_2$, $e_2^2$ is a basis of $S^2(\Complex^2)$ we can write
    \[
        x
      =   \lambda_1 e_1^2
        + \lambda_2 e_1 e_2
        + \lambda_3 e_2^2
    \]
    with unique $\lambda_1, \lambda_2, \lambda_3 \in \Complex$.
    
    We first notice that $e_1 e_2 \in U$:
    If $\lambda_2 \neq 0$ we
    \[
        e_1 e_2
      = \frac{1}{2 \lambda_2} \cdot (x - A.x)
      \in U
    \]
    for
    \[
                A
      \coloneqq \begin{pmatrix}
                  1 &  0 \\
                  0 & -1
                \end{pmatrix}
      \in       \GL_2(\Complex).
    \]
    If $\lambda_2 = 0$ we have $x = \lambda_1 e_1^2 + \lambda_3 e_2^2$.
    In the case of $\lambda_3 = 0$ we then have $\lambda_1 \neq 0$, thus $e_1^2 \in U$ and therefore
    \[
          e_1 e_2
      =   \frac{1}{2} \left(
                        B.\left( e_1^2 \right) - e_1^2 - C.\left( e_1^2 \right)
                      \right)
      \in U
    \]
    for the matrices $B, C \in \GL_2(\Complex)$ with
    \[
        B
      = \begin{pmatrix}
          1 & 0 \\
          1 & 1
        \end{pmatrix}
      \text{ and }
        C
      = \begin{pmatrix}
          0 & 1 \\
          1 & 0
        \end{pmatrix}
    \]
    If $\lambda_3 \neq 0$ we have
    \[
          e_1 e_2
      =   \frac{1}{4 \lambda_3} E.(D.x - x)
      \in U
    \]
    for the matrices $D, E \in \GL_2(\Complex)$ with
    \[
        D
      = \begin{pmatrix}
          1 & 1 \\
          0 & 1
        \end{pmatrix}
      \text{ and }
        E
      = \begin{pmatrix}
          2 & -1 \\
          0 &  1
        \end{pmatrix}.
    \]
    Since $e_1 e_2 \in U$ we also have
    \begin{gather*}
          e_1^2
      =   A.(e_1 e_2) - e_1 e_2
      \in U
    \shortintertext{for}
                A
      \coloneqq \begin{pmatrix}
                  1 & 1 \\
                  0 & 1
                \end{pmatrix}
      \in       \GL_2(\Complex)
    \end{gather*}
    as well as
    \begin{gather*}
          e_2^2
      =   B.(e_1 e_2) - e_1 e_2
      \in U
    \shortintertext{for}
                B
      \coloneqq \begin{pmatrix}
                  1 & 0 \\
                  1 & 1
                \end{pmatrix}
      \in       \GL_2(\Complex) \,.
    \end{gather*}
    So $U$ contains a basis of $S^2(\Complex^2)$ and therefore $U = \Complex^2$.
  \end{proof}
  
  As a representation of $\GL_2(\Complex) \times S_2$ we now have
  \[
          V
    \cong         S^2\left( \Complex \right) \boxtimes_\Complex \Complex
          \oplus  \Lambda^2\left( \Complex \right) \boxtimes_\Complex \sgn.
  \]
\end{expl}


In this section let $k$ be an infinite field.
For a $k$-vector space $V$ and $d \geq 1$ we let $\GL(V)$ act on $V^{\otimes d}$ in the usual way, i.e.\
\[
    \psi.(v_1 \otimes \dotsb \otimes v_d)
  = (\psi.v_1) \otimes \dotsb \otimes (\psi.v_d)
\]
for all $\psi \in \GL(V)$ and simple tensors $v_1 \otimes \dotsb \otimes v_d \in V^{\otimes d}$.
This turns $V^{\otimes d}$ into a representation of $\GL(V)$.
We can also turn $V^{\otimes d}$ into a representation of $S_d$ with
\[
    \pi.(v_1 \otimes \dotsb \otimes v_d)
  = v_{\pi(1)} \otimes \dotsb \otimes v_{\pi(d)}
\]
for every permutation $\pi \in S_d$ and simple tensors $v_1 \otimes \dotsb \otimes v_d \in V^{\otimes d}$. 
Is is clear that the actions of $\GL(V)$ and $S_d$ commute.

\begin{theorem}(Schur--Weyl duality)
  Let $\gen{\GL(V)}$ denote the image of the algebra homomorphism
  \[
            k \GL(V)
    \to     \End_k\left( V^{\otimes d} \right),
    \quad   g
    \mapsto (x \mapsto g.x)
  \]
  and $\gen{S_d}$ the image of the algebra homomorphism
  \[
            k S_d
    \to     \End_k\left( V^{\otimes d} \right),
    \quad   \sigma
    \mapsto (x \mapsto \sigma.x).
  \]
  \begin{enumerate}[label=\emph{(\alph*)}, leftmargin=*]
    \item \label{enum: end sd = gl}
      $\End_{S_d}(V^{\otimes d}) = \gen{\GL(V)}$.
    \item \label{enum: end gl = sd}
      If $\kchar k = 0$ or $\kchar k > d$ then $\End_{\GL(V)}(V^{\otimes d}) = \gen{S_d}$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  We first prove \ref{enum: end gl = sd} assuming \ref{enum: end sd = gl}:
  $V^{\otimes d}$ is a finite-dimenisonal representation of $S_d$ over $k$, where $\kchar k = 0$ or $\kchar k > d$.
  The group algebra $k S_d$ is semisimple by Maschke’s theorem, so $V^{\otimes d}$ is completely reducible as a $k S_d$-module.
  Since $k S_d$ is semisimple and $A \coloneqq \gen{S_d} \subseteq \End_k(V^{\otimes d})$ is a quotient of $k S_d$ we find that $A$ is also semisimple.
  By \ref{enum: end sd = gl} we have $A' = \gen{GL(V)}$ where $A'$ denotes the commutator of $A$ in $\End_k(V^{\otimes d})$.
  Applying the double centralizer theorem we find that
  \[
      \End_{\GL(V)}\left( V^{\otimes d} \right)
    = \gen{\GL(V)}'
    = A''
    = A
    = \gen{S_d}.
  \]
  
  Now we show \ref{enum: end sd = gl}:
  We have an isomorphism of $k$-vector spaces
  \begin{align*}
              \Phi
    \colon    (\End_k(V))^{\otimes d}
    &\to      \End_k\left( V^{\otimes d} \right), \\
              f_1 \otimes \dotsb \otimes f_d
    &\mapsto  f_1 \otimes \dotsb \otimes f_d \,.
  \end{align*}
  Now both $\End_k(V)^{\otimes d}$ and $\End_k\left( V^{\otimes d} \right)$ are representations of $S_d$ in the usual way, i.e.\
  \[
      \pi.(f_1 \otimes \dotsb \otimes f_d)
    = f_{\pi(1)} \otimes \dotsb \otimes f_{\pi(d)}
  \]
  for all permutations $\pi \in S_d$ and simple tensors $f_1 \otimes \dotsb \otimes f_d \in \End_k(V)^{\otimes d}$, and
  \[
      (\pi.f)(x)
    = \pi.f\left( \pi^{-1}.x \right)
  \]
  for all permutations $\pi \in S_d$, $f \in \End_k(V^{\otimes d})$ and $x \in V^{\otimes d}$.
  $\Phi$ is also $G$-equivarint, since for every permutation $\pi \in S_d$ and simple tensors $f_1 \otimes \dotsb \otimes f_d \in \End_k(V)^{\otimes d}$, $v_1 \otimes \dotsb \otimes v_d \in V^{\otimes_d}$
  \begin{align*}
     &\,  \Phi(\pi.(f_1 \otimes \dotsb \otimes f_d))(v_1 \otimes \dotsb \otimes v_d) \\
    =&\,  \Phi\left( f_{\pi(1)} \otimes \dotsb \otimes f_{\pi(d)} \right)(v_1 \otimes \dotsb \otimes v_d) \\
    =&\,  f_{\pi(1)}(v_1) \otimes \dotsb \otimes f_{\pi(d)}(v_d)
  \shortintertext{and}
     &\,  (\pi.\Phi(f_1 \otimes \dotsb \otimes f_d))(v_1 \otimes \dotsb \otimes v_d) \\
    =&\,  \pi.\Phi(f_1 \otimes \dotsb \otimes f_d)\left( \pi^{-1}.(v_1 \otimes \dotsb \otimes v_d) \right) \\
    =&\,  \pi.\Phi(f_1 \otimes \dotsb \otimes f_d)\left( v_{\pi^{-1}(1)} \otimes \dotsb \otimes v_{\pi^{-1}(d)} \right) \\
    =&\,  \pi.\left( f_1\left(v_{\pi^{-1}(1)}\right) \otimes \dotsb \otimes f_d\left(v_{\pi^{-1}(d)}\right) \right) \\
    =&\,  f_{\pi(1)}(v_1) \otimes \dotsb \otimes f_{\pi(d)}(v_d)0\,.
  \end{align*}
  So $\Phi$ is an isomorphism of representations of $S_d$. It follows that $\Phi$ induces an isomorphism
  \[
          \left( \End_k(V)^{\otimes d} \right)^{S_d}
    \cong \End_k \left(V^{\otimes d}\right)^{S_d}.
  \]
  Hence
  \begin{align*}
          \End_{S_n}\left( V^{\otimes d} \right)
    &=    \left( \End_k\left( V^{\otimes d} \right) \right)^{S_n}
    \cong \left( \End_k(V)^{\otimes d} \right)^{S_n} \\
    &=    \text{symmetric tensors in $\End_k(V)^{\otimes d}$} \,.
  \end{align*}
  
  Now $\gen{\GL(V)} \subseteq \End_k(V^{\otimes d})$ is generated as an $k$-vector space by the image of the group homomorphism $\GL(V) \to \GL(V^{\otimes d})$.
  (Since $\GL(V)$ is a $k$-basis of $k\GL(V)$, the image of $\GL(V)$ under the algebra homomorphism $k \GL(V) \to \End_k(V)$ generated $\gen{\GL(V)}$ as a $k$-vector space.
  The image of $\GL(V)$ under this algebra homomorphism is precisely the image of $\GL(V)$ under the group homomorphism.)
  Since the image of $\psi \in \GL(V)$ under this group homomorphism is given by $\psi \otimes \dotsb \otimes \psi$ we need to show that
  \[
      \left( \End_k(V)^{\otimes d} \right)^{S_d}
    = \vspan_k  \{
                  \psi \otimes \dotsb \otimes \psi
                \mid
                  \psi \in \GL(V)
                \} \,.
  \]
  Since $\GL_k(V) \subseteq \End_k(V)$ is Zariski dense over $k$ this will follow from Lemma \ref{lemma: symmetric tensors and zariski dense subsets}
\end{proof}


\begin{lemma}\label{lemma: symmetric tensors and zariski dense subsets}
  Let $k$ be an infinite field, $d \geq 1$, $E$ a finite-dimensional $k$-vector space and $X \subseteq E$ Zariski-dense over $k$.
  Then the symmetric tensors in $E^{\otimes d}$ are generated as a $k$-vector space by the tensors $x \otimes \dotsb \otimes x$ where $x \in X$.
\end{lemma}
\begin{proof}
  Let $e_1, \dotsc, e_n$ be a $k$-basis of $E$, $S \subseteq E^{\otimes d}$ the vector subspace of symmetric tensors (i.e.\ $S = (E^{\otimes d})^{S_n}$) and
  \[
              U
    \coloneqq \vspan_k \{ x \otimes \dotsb \otimes x \mid x \in X \}
    \subseteq E^{\otimes d} \,.
  \]
  For every partition $\lambda \in \N^n$ with $|\lambda| = d$ we write
  \[
      e^\lambda
    =         \underbrace{e_1 \otimes \dotsb \otimes e_1}_{\lambda_1}
      \otimes \underbrace{e_2 \otimes \dotsb \otimes e_2}_{\lambda_2}
      \otimes \dotsb
      \otimes \underbrace{e_n \otimes \dotsb \otimes e_n}_{\lambda_n} \,.
  \]
  as well as
  \[
      a^\lambda
    = \sum_{y \in S_d e^\lambda} y
    = \sum \text{distinct permutations of $e^\lambda$} \,,
  \]
  where $S_d e^\lambda$ denotes the orbit of $e^\lambda$.
  It is easy to see that $\{ a^\lambda \mid \lambda \in \N^n, |\lambda| = d \}$ is a $k$-basis of $S$.
  It is clear that $U \subset S$ and to show the other inclusion is suffices to show that every $k$-linear map $f \colon S \to k$ which vanishes on $U$ is the zero map.
  
  To show this let $p \in k[X_1, \dotsc, X_d]$ be defined as
  \[
      p(X_1, \dotsc, X_d)
    = \sum_{\substack{\lambda \in \N^n \\ |\lambda| = d}}
        f\left( a^\lambda \right)
        X_1^{\lambda_1} \dotsm X_n^{\lambda_n}
  \]
  and $\tilde{\lambda} \colon E \to k$ as the corresponding polynomial function
  \[
      \tilde{\lambda}\left( \sum_{i=1}^n \mu_i e_i \right)
    = p(\mu_1, \dotsc, \mu_n) \,.
  \]
  It is clear that $\tilde{\lambda} \in \Pol_k(E)$.
  For every $x = \sum_{i=1}^n x_i e_i \in X$ we have
  \[
      \tilde{\lambda}(x)
    = p(x_1, \dotsc, x_n)
    = \sum_{\substack{\lambda \in \N^n \\ |\lambda| = d}}
        x_1^{\lambda_1} \dotsm x_n^{\lambda_n}
        f\left( a^\lambda \right) 
    = f(x \otimes \dotsb \otimes x)
    = 0 \,.
  \]
  Since $X$ is Zariski dense in $E$ we find that $\tilde{\lambda} = 0$.
  Therefore $p = 0$ and thus $f(a^\lambda) = 0$ for every $\lambda \in \N^n$ with $|\lambda| = d$.
  So $f_{|S} = 0$.
\end{proof}


\begin{corollary}
  Let $k$ be a field with $\kchar k = 0$ (in particular $k$ is infinite) and $V$ a finite-dimensional $k$-vector space.
  Then $V^{\otimes d}$ is a representation of $S_d \times \GL(V)$ and we have a decomposition into irreducible representations of $S_d \times \GL(V)$ with
  \[
          V^{\otimes d}
    \cong \bigoplus_{\lambda \in \Delta} S_\lambda \otimes V_\lambda
  \]
  where the $S_\lambda$ are irreducible representations of $S_d$, the $V_\lambda$ are irreducible representations of $\GL(V)$ and the $S_\lambda \otimes V_\lambda$ are irreducible representations of $S_d \times \GL(V)$, where $\Delta$ is a complete set of representatives of $\Irr(S_d)$.
\end{corollary}
\begin{proof}
  This follows directly from the Schur--Weyl Duality and the Double Centralizer Theorem.
\end{proof}

(The last few lectures, in which some basic facts about the irreducible representations of the symmetric group $S_n$ were presented without (much) proof, are missing from these notes.)




