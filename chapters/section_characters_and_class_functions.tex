\section{Characters}





\subsection{General Definitions and Properties}


\begin{conventions}
  In the following $k$ denotes a field and $A$ a $k$-algebra, and $M, N$ denote finite-dimensionl $R$-modules.
\end{conventions}


\begin{definition}
  Let
  \[
            \rho
    \colon  A
    \to     \End_k(M),
    \quad   a
    \mapsto (m \mapsto am)
  \]
  be the canonical homomorphism.
  Then the \emph{character of $M$} is the $k$-linear map
  \[
            \chi_M
    \colon  A
    \to     k,
    \quad   a
    \mapsto \tr \rho(a) \,.
  \]
\end{definition}


\begin{lemma}
  \leavevmode
  \label{lemma: properties of general characters}
  \begin{enumerate}
    \item
      We have that $\chi_M(1) = \dim M$ (as elements of $k$).
    \item
      If $M \cong N$ as $A$-modules then $\chi_M = \chi_N$.
    \item
      \label{enumerate: character of direct sum}
      We have that $\chi_{M \oplus N} = \chi_M + \chi_N$.
    \item
      \label{enumerate: character of quotient}
      If $N$ is a submodule of $M$ then $\chi_M = \chi_M + \chi_{M/N}$.
%     \item
%       We have $\chi_{V \otimes W} = \chi_V \cdot \chi_W$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  For every occuring module $P$ of $A$ let
  \[
            \rho_P
    \colon  A
    \to     \End_k(P),
    \quad   a
    \mapsto (p \mapsto ap)
  \]
  be the corresponding canonical homomorphism.
  \begin{enumerate}
    \item
      This follows from $\rho_M(1) = \id_M$.
    \item
      Let $m_1, \dotsc, m_r$ be a $k$-basis of $M$ and let $\varphi \colon M \to N$ be an isomorphism of $A$-modules.
      Then $\varphi$ is in particular an isomorphism of $k$-vector spaces and it follows that $\varphi(m_1), \dotsc, \varphi(m_r)$ is a $k$-basis of $N$.
      Let $a \in A$ and let $B \in \Mat_r(k)$ be the matrix which represents the endomorphisms $\rho_M(a) \colon M \to M$ with respect to the basis $m_1, \dotsc, m_r$.
      Then $B$ also represents the endomorphism $\rho_N(a)$ with respect to the basis $\varphi(m_1), \dotsc, \varphi(m_r)$ bcause $\varphi$ is an isomorphism of $A$-modules.
      It follows that
      \[
          \chi_M(a)
        = \tr \rho_M(a)
        = \tr B
        = \tr \rho_N(a)
        = \chi_N(a) \,.
      \]
    \item
      Let $m_1, \dotsc, m_r$ be a $k$-basis of $M$ and let $n_1, \dotsc, n_s$ be a $k$-basis of $N$.
      Let $a \in A$, let $B_1 \in \Mat_r(k)$ be the matrix which represents the endomorphism $\rho_M(a)$ with respect to the basis $m_1, \dotsc, m_r$ and let $B_2 \in \Mat_s(k)$ be the matrix which represents the endomorphism $\rho_N(a)$ with respect to the basis $n_1, \dotsc, m_s$.
      It follows that
      \[
                  B
        \defined  \begin{bmatrix}
                    B_1 & 0 \\
                    0   & B_2
                  \end{bmatrix}
        \in       \Mat_{r+s}(k) \,.
      \]
      is the matrix which represents the endomorphism $\rho_{M \oplus N}(a)$ with respect to the basis $(m_1, 0), \dotsc, (m_r, 0), (0, n_1), \dotsc, (0, n_s)$ of $M \oplus N$.
      It follows that
      \begin{align*}
            \chi_{M \oplus N}(a)
        &=  \tr \rho_{M \oplus N}(a)
         =  \tr B
         =  \tr B_1 + \tr B_2 \\
        &=  \tr \rho_M(a) + \tr \rho_N(a)
         =  \chi_M(a) + \chi_N(a) \,.
      \end{align*}
    \item
      Let $m_1, \dotsc, m_r$ be a basis of $M$ such that for $s = \dim N$ the vectors $m_1, \dotsc, m_s$ are a basis of $N$.
      Then the residue classes $\class{m_{s+1}}, \dotsc, \class{m_r}$ are a $k$-basis of $V/U$.
      Let $a \in A$ and let $B \in \Mat_r(k)$ be the matrix which represents $\rho_M(a)$ with respect to $m_1, \dotsc, m_r$.
      Then $B$ is of the form
      \[
          B
        = \begin{bmatrix}
            B_1 & * \\
            0 & B_2
          \end{bmatrix}
      \]
      where $B_1 \in \Mat_s(k)$ is the matrix which represents $\rho_N(a)$ with respect to the basis $m_1, \dotsc, m_s$ and $B_2 \in \Mat_{r-s}(k)$ is the matrix which represents $\rho_{M/N}(a)$ with respect to the basis $\class{m_{s+1}}, \dotsc, \class{m_r}$.
      It follows that
      \begin{align*}
            \chi_M(a)
        &=  \tr \rho_M(a)
         =  \tr B
         =  \tr B_1 + \tr B_2 \\
        &=  \tr \rho_N(a) + \tr \rho_{V/U}(a)
         =  \chi_U(a) + \chi_{V/U}(a).
      \end{align*}
      This proves the claim.
    \qedhere
  \end{enumerate}
\end{proof}


\begin{remark}
  It follows from part~\ref*{enumerate: character of quotient} that $\chi_M = \chi_N + \chi_P$ for every short exact sequence of finite-dimensional $A$-modules
  \[
        0
    \to N
    \to M
    \to P
    \to 0 \,.
  \]
  Part~\ref*{enumerate: character of direct sum} then follows from part~\ref*{enumerate: character of quotient} by using the standard short exact sequence
  \[
        0
    \to M
    \to M \oplus N
    \to N
    \to 0 \,.
  \]
\end{remark}


\begin{recall}
  Recall from linear algebra that for any two endomorphisms $f, g \colon V \to V$ of a finite-dimensional $k$-vector space $V$ it holds that
  \[
    \tr(fg) = \tr(gf) \,.
  \]
\end{recall}


\begin{warning}
  It does not hold that
  \[
      \tr(f_1 \dotsm f_n)
    = \tr(f_{\sigma(1)} \dotsm f_{\sigma(n)})
  \]
  for all endomorphisms $f_1, \dotsc, f_n \colon V \to V$ and $\sigma \in S_n$.
  The above formula only generalizes to
  \[
      \tr(f_1 f_2 \dotsm f_n)
    = \tr(f_2 \dotsm f_n f_1) \,,
  \]
\end{warning}


\begin{definition}
  The \emph{commutator} of two elements $a, b \in A$ is
  \[
              [a,b]
    \defined  ab - ba \,.
  \]
  The \emph{commutator} subspace of $A$ is
  \[
              [A,A]
    \defined  \gen{ [a,b] \suchthat a, b \in A }_k \,.
  \]
\end{definition}


\begin{remark}
  One can define for more generally for every two subsets $X, Y \subseteq A$ the commutator $[X, Y] = \gen{ [x,y] \suchthat x \in X, y \in Y}_k$, but we will not need this.
\end{remark}


\begin{lemma}
  For the $k$-algebra $\Mat_n(k)$ the commutator $[\Mat_n(k), \Mat_n(k)]$ is the $k$-linear subspace of codimension $1$ given by
  \[
              \sllie_n(k)
    \defined  \ker \tr
    =         \{
                M \in \Mat_n(k)
              \suchthat
                \tr M = 0
              \} \,.
  \]
\end{lemma}


\begin{proof}
  For all $A, B \in \Mat_n(k)$ we have that
  \[
      \tr( [A,B] )
    = \tr(AB - BA)
    = \tr(AB) - \tr(BA)
    = \tr(AB) - \tr(AB)
    = 0 \,.
  \]
  Since these elements generate $\sllie_n(k)$ as a $k$-vector space it follows that $\sllie_n(k) \subseteq \ker \tr$.
  
  To show the other inclusion let $(E_{ij})_{1 \leq i,j \leq n}$ be thsandard basis of $\Mat_n(k)$.
  Then the matrices $E_{ij}$ for $i \neq j$ together with the matrices $E_{ii} - E_{i+1,i+1}$ for $i = 1, \dotsc, n-1$ form a $k$-basis of $\ker \tr$.
  For all  $i \neq j$ we have that
  \[
        E_{ij}
    =   E_{ii} E_{ij} - \underbrace{E_{ij} E_{ii}}_{=0}
    =   [E_{ii}, E_{ij}]
    \in \sllie_n(k) \,,
  \]
  and for all $i = 1, \dotsc, n-1$ we have that
  \[
        E_{ii} - E_{i+1,i+1}
    =   E_{i,i+1} E_{i+1,i} - E_{i+1,i} E_{i,i+1}
    =   [E_{i,i+1}, E_{i+1,i}]
    \in \sllie_n(k) \,.
  \]
  This shows that $\ker \tr \subseteq \sllie_n(k)$.
  
  That $\sllie_n(k) = \ker \tr$ has codimension $1$ in $\Mat_n(k)$ (i.e.\ has dimension $n^2 - 1$) follows from the fact that $\tr \colon \Mat_n(k) \to k$ is a surjective linear map.
\end{proof}


\begin{remark}
  The notation $\sllie_n(k)$ comes from the fact that $\sllie_n(k)$ is the Lie algebra of the special linear group $\SL_n(k)$.
\end{remark}


\begin{remark}
  It can be shown that every element of $\sllie_n(K)$ is already a commutator itself, so that
  \[
      \sllie_n(k)
    = \{ [A,B] \suchthat A, B \in \Mat_n(k) \} \,.
  \]
  This is proven in \cite{TraceZero}.
\end{remark}


\begin{lemma}
  Let $A$ and $B$ be $k$-algebras.
  Then
  \[
      [A \times B, A \times B]
    = [A,A] \oplus [B,B].
  \]
  as $k$-vector subspaces of $A \times B$.
\end{lemma}
\begin{proof}
  For all $a, a' \in A$ and $b, b' \in B$ we have that
  \begin{align*}
        [(a,b),(a',b')]
    &=  (a,b)(a',b') - (a',b')(a,b)
     =  (aa',bb') - (a'a, b'b) \\
    &=  (aa'-a'a, bb' - b'b)
     =  ([a,a'], [b,b']) \,.
  \end{align*}
  It follows that
  \begin{align*}
        [A \times B, A \times B]
    &=  \gen{
          [(a,b), (a',b')]
        \suchthat
          (a,b), (a',b') \in A \times B
        }_k \\
    &= \gen{
          ([a,a'], [b,b'])
        \suchthat
          a, a' \in A
          \text{ and }
          b, b' \in B
        }_k \\
    &=  \gen{ [a,a'] \mid a, a' \in A }_k
        \oplus
        \gen{ [b,b'] \mid b, b' \in B }_k \\
    &= [A,A] \oplus [B,B]
  \end{align*}
  which proves the claim.
\end{proof}


\begin{corollary}
  \label{corollary: commutator product of matrix algebras}
  For all $r \geq 1$ and $n_1, \dots, n_r \geq 0$ the commutator of
  \[
              A
     \defined \Mat_{n_1}(k) \oplus \dotsb \oplus \Mat_{n_r}(k)
  \]
  is the $k$-linear subspace of codimension $r$ given by
  \[
        [A,A]
     =  \sllie_{n_1}(k) \oplus \dotsb \oplus \sllie_{n_r}(k) \,.
  \]
\end{corollary}


\begin{lemma}
  \label{lemma: characters are zero on commutators}
  For every $a \in [A,A]$ we have that $\chi_M(a) = 0$.
\end{lemma}


\begin{proof}
  Let $a, b \in A$.
  Then
  \begin{align*}
        \chi_M([a,b])
    &=  \chi_M(ab - ba)
     =  \chi_M(ab) - \chi_M(ba) \\
    &=  \tr \rho(ab) - \tr \rho(ba)
     =  \tr( \rho(a) \rho(b) ) - \tr( \rho(b) \rho(a) )
     =  0 \,.
  \end{align*}
  Since $[A,A]$ is generated by the commutators $[a,b]$ as a $k$-vector space it follows that $\chi_M(a) = 0$ for all $a \in [A,A]$.
\end{proof}


\begin{fluff}
  It follows from Lemma~\ref{lemma: characters are zero on commutators} that every character $\chi_M \colon A \to k$ factors through a $k$-linear map $A/[A,A] \to k$, and can therefore be regarded as an element of $(A/[A,A])^*$.
  We will often not distinguish between $\chi_M$ as a $k$-linear map $A \to k$ and a $k$-linear map $A/[A,A] \to k$.
\end{fluff}


\begin{definition}
  If $M$ is a simple finite-dimensional $A$-module then its character $\chi_M$ is \emph{irreducible}.
\end{definition}


\begin{theorem}
  \leavevmode
  \label{theorem: characters as a basis}
  \begin{enumerate}
    \item
      \label{enumerate: characters are linearly independent}
      If $\kchar k = 0$ or $k$ is algebraically closed then the irreducible characters of $A$ are linearly idependent.
    \item
      If $k$ is algebraically closed and $A$ is finite-dimensional and semisimple then the irreducible chararacters form a $k$-basis of $(A/[A,A])^*$.
  \end{enumerate}
\end{theorem}


\begin{proof}
  \leavevmode
  \begin{enumerate}
    \item
      Let $M_1, \dotsc, M_r$ be pairwise non-isomorphic finite-dimensional simple $A$-modules and let $\sum_{i=1}^r \lambda_i \chi_{M_i} = 0$.
      
      Suppose first that $\kchar k = 0$
      Then there exists by Corollary~\ref{corollary: existence of projection operators} for every $i = 1, \dotsc, r$ some $a_i \in A$ wich acts on $M_i$ as the identity and on $M_j$ for $j \neq i$ as the zero endomorphism.
      It follows that
      \[
          \chi_{M_i}(a_j)
        = \delta_{ij} \dim M_i
      \]
      for all $i, j = 1, \dotsc, r$.
      It follows that
      \[
          0
        = \sum_{i=1}^r \lambda_i \chi_{M_i}(a_j)
        = \lambda_i \dim M_i
      \]
      for all $i = 1, \dotsc, r$, and thus $\lambda_i = 0$ for all $i = 1, \dotsc, r$ because $\kchar k \neq 0$.
      
      Suppose that $k$ is algebraically closed.
      For every $i = 1, \dotsc, r$ let $f_i \in \End_k(M_i)$ be an endomorphism with $\tr(f_i) = 1$.
      It follows from the \hyperref[theorem: density theorem]{density theorem} that there exists for every $i = 1, \dotsc, r$ some $a_i \in A$ which acts on $M_i$ by $f_i$ and on $M_j$ with $j \neq i$ by the zero endomorphism.
      It follows that
      \[
          \chi_{M_i}(a_j)
        = \delta_{ij}
      \]
      and therefore that
      \[
          0
        = \sum_{i=1}^r \lambda_i \chi_{M_i}(a_j)
        = \lambda_i
      \]
      for all $i = 1, \dotsc, r$.
    \item
      There exists $r \geq 0$ and $n_1, \dotsc, n_r \geq 1$ such that $A \cong \Mat_{n_1}(k) \times \dotsb \times \Mat_{n_r}(k)$ by Corollary~\ref{corollary: semisimple algebra product of matrix algebras}.
      It follows that $A$ has precisely $r$ simple module up to isomorphism, whose characters are linearly independent by part~\ref*{enumerate: characters are linearly independent}.
      It also follows from Corollary~\ref{corollary: commutator product of matrix algebras} that $\dim A/[A,A] = r$ and therefore that $\dim (A/[A,A])^* = r$.
      We therefore form a $k$-basis of $(A/[A,A])^*$.
    \qedhere
  \end{enumerate}
\end{proof}


\begin{corollary}
  Suposse that $\kchar k = 0$ and that $M, N$ are semisimple.
  If $\chi_M = \chi_N$ then $M \cong N$.
\end{corollary}


\begin{proof}
  Let $M \cong S_1^{\oplus m_1} \oplus \dotsb \oplus S_r^{\oplus m_r}$ and $N \cong S_1^{\oplus n_1} \oplus \dotsb \oplus S_r^{\oplus n_r}$ as $A$-modules for pairwise non-isomorphic finite-dimensional simple $A$-modules $S_1, \dotsc, S_r$.
  Then
  \begin{align*}
    \chi_M &= m_1 \chi_{S_1} + \dotsb + m_r \chi_{S_r}  \\
    \chi_N &= n_1 \chi_{S_1} + \dotsb + n_r \chi_{S_r}
  \end{align*}
  and it follows that $m_i = n_i$ for all $i = 1, \dotsc, r$ in $k$.
  It follows from $\kchar k = 0$ that already $m_i = n_i$ for all $i = 1, \dotsc, r$.
\end{proof}


\begin{fluff}
  With this we have seen that finite-dimensional semisimple $A$-modules can be distinguished by they characters.
  For non-semisimple modules this does not work because every finite-dimensional $A$-modules shares it character with some semi-simeple $A$-module, as we will show below.
  So from the point of characters every finite-dimensional $A$-module looks semisimple.
\end{fluff}


\begin{corollary}
  \label{corollary: characters for filtrations}
  Let
  \[
                0
    =           M_0
    \moduleleq  M_1
    \moduleleq  \dotsb
    \moduleleq  M_r
    =           M
  \]
  be a filtration of $M$ with factors $N_i = M_i/M_{i-1}$ for all $i = 1, \dotsc, r$.
  Then
  \[
      \chi_M
    = \chi_{N_1} + \dotsb + \chi_{N_r} \,.
  \]
\end{corollary}


\begin{corollary}
  There exists a finite-dimensional semisimple module $M'$ with
  \[
    \chi_M = \chi_{M'} \,.
  \]
\end{corollary}


\begin{proof}
  It follows from the finite-dimensionality of $M$ that there exist a composition series
  \[
                  0
    =             M_0
    \modulelneq   M_1
    \modulelneq   \dotsb
    \modulelneq   M_r
    =             M
  \]
  of $M$, i.e.\ the factors $M'_i \defined M_i/M_{i-1}$ are simple for all $i = 1, \dotsc, r$.
  It then follows from Corollary~\ref{corollary: characters for filtrations} that
  \[
      \chi_M
    = \chi_{M'_1} + \dotsb + \chi_{M'_r}
    = \chi_{M'_1 \oplus \dotsb \oplus M'_r}
    = \chi_{M'}
  \]
  with $M' \defined M'_1 \oplus \dotsb \oplus M'_r$ being semisimple.
\end{proof}





\subsection{Frobenius Algebras}


\begin{fluff}
  We will now show that for certain kind of particularly nice $k$-algebras the space $(A/[A,A])^*$ can be identified with the center $\ringcenter(A)$.
\end{fluff}


\begin{definition}
  A bilinear form $(-,-) \colon A \times A \to k$ is \emph{associative} if $(ab,c) = (a,bc)$ for all $a, b c \in A$.
\end{definition}


\begin{lemma}
  \label{lemma: correspondence assiative bf and linear maps}
  The maps
  \begin{align*}
    \{ \text{associative bilinear forms $A \times A \to k$} \}
    &\longleftrightarrow
    \{ \text{linear forms $A \to k$} \}
    \\
    (-,-)
    &\longmapsto
    (1,-)
    \\
    ((a,b) \mapsto \varepsilon(ab))
    &\mapsfrom
    \varepsilon
  \end{align*}
  are well-defined mutually inverse bijections.
\end{lemma}


\begin{proof}
  Both maps are well-defined.
  If $(-,-) \colon A \times A \to k$ is an associative bilinear form then for $\varepsilon \colon A \to k$ we have that
  \[
      \varepsilon(ab)
    = (1,ab)
    = (a,b)
  \]
  for all $a, b \in A$.
  If $\varepsilon \colon A \to k$ is a linear form then for the bilinear map $(-,-) \colon A \times A \to k$ with $(a,b) = \varepsilon(ab)$ we have that
  \[
      (1,-)
    = \varepsilon(1 \cdot (-))
    = \varepsilon(-)
    = \varepsilon \,.
  \]
  This shows that the maps are mutually inverse.
\end{proof}


\begin{remark}
  If $(-,-) \colon A \times A \to k$ is an associative bilinear form then
  \[
      (1,a)
    = (1, a \cdot 1)
    = (1 \cdot a, 1)
    = (1, a)
  \]
  for all $a \in A$, and thus $(1,-) = (-,1)$.
  We have therefore made no unnecessary choice by using $(1,-)$ instead of $(-,1)$ in Lemma~\ref{lemma: correspondence assiative bf and linear maps}.
\end{remark}


\begin{definition}
  A linear form $\varepsilon \colon A \to k$ is \emph{symmetric} if $\varepsilon(ab) = \varepsilon(ba)$ for all $a, b \in A$.
\end{definition}


\begin{lemma}
  An associative bilinear form $(-,-) \colon A \times A \to k$ is symmetric if and only if the corresponding linear form $\varepsilon \colon A \to k$ is symmetric.
\end{lemma}


\begin{recall}
  Recall from linear algebra that a bilinear form $(-,-) \colon V \times W \to k$ on $k$-vector spaces $V,W$ is \emph{non-degenerate in the first variable} if one (and thus all) of the following conditions are satisfied:
  \begin{enumerate}
    \item
      For all $v_1, v_2 \in V$ with $v_1 \neq v_2$ there exists some $w \in W$ with $(v_1, w) \neq (v_2, w)$.
    \item
      For every nonzero $v \in V$ there exists some $w \in W$ with $(v,w) \neq 0$.
    \item
      The linear map $V \to W^*$, $v \mapsto (v,-)$ is injective.
  \end{enumerate}
  That $(-,-)$ is \emph{non-degenerate in the second variable} is defined is a similar way.
  The bilinear form $(-,-)$ is \emph{non-degenerate} if it is non-degenerate in both variables.
  
  If $V, W$ are finite-dimensional with $\dim V = \dim W$ then $(-,-)$ is non-degenerate in the first variable if and only if it is non-degenerate in the second variable.
  In this case all three of the above notions coincide.
  
  If $V,W$ are finite-dimensional then the bilinear form $(-,-)$ is non-degenerate if and only if $\dim V = \dim W$ and for one basis $v_1, \dotsc, v_n$ of $V$ there exists a dual basis $w_1, \dotsc, w_n$ of $W$ with
  \[
      (v_i, w_j)
    = \delta_{ij}
  \]
  for all $i,j = 1, \dotsc, n$.
  It then follows that there exists for every basis of $V$ a unique corresponding dual basis of $W$, which leads to a bijection between the sets of basis of $V$ and $W$.
\end{recall}



\begin{lemma}
  \label{proposition: nondegenerate for linear forms}
  Let $(-,-) \colon A \times A \to k$ be an associative bilinear form with corresponding linear form $\varepsilon \colon A \to k$.
  Then the following conditions are equivalent:
  \begin{enumerate}
    \item
      \label{enumerate: non-degenerate in the first variable}
      The bilinear form $(-,-)$ is non-degenerate in the first variable.
    \item
      \label{enumerate: a on the left}
      For every nonzero $a \in A$ there exists some $b \in A$ with $\varepsilon(ab) \neq 0$.
    \item
      \label{enumerate: no right ideal in kernel}
      The kernel $\ker \varepsilon$ contains no nonzero right ideal of $A$.
  \end{enumerate}
  Similarly, the following conditions are equivalent:
  \begin{enumerate}
    \item
      The bilinear form $(-,-)$ is non-degenerate in the second variable.
    \item
      For every nonzero $a \in A$ there exists some $b \in A$ with $\varepsilon(ba) \neq 0$.
    \item
      The kernel $\ker \varepsilon$ contains no nonzero left ideal of $A$.
  \end{enumerate}
\end{lemma}


\begin{proof}
  \leavevmode
  \begin{description}
    \item[\ref*{enumerate: non-degenerate in the first variable} $\iff$ \ref*{enumerate: a on the left}]
      This follows from the fact that $(a,b) = \varepsilon(ab)$ for all $a, b \in A$.
    \item[\ref*{enumerate: a on the left} $\iff$ \ref*{enumerate: no right ideal in kernel}]
      That $\ker(\varepsilon)$ contains no nonzero right ideal is equivalent to $\ker(\varepsilon)$ containing no nonzero principal right ideal, i.e.\ no nonzero right ideal of the form $a A$ with $a \in A$.
      This happens if and only if for every $a \in A$ there exists some $b \in A$ with $ab \notin \ker(\varepsilon)$, i.e.\ $\varepsilon(ab) \neq 0$.
  \end{description}
  The eqivalence of the other three conditions can be shown in the same way.
\end{proof}


\begin{corollary}
  A bilinear form $(-,-) \colon A \times A \to k$ is associative, symmetric and non-degenerate if and only if the corresponding linear form $\varepsilon \colon A \to k$ is symmetric and satisfies one (and thus all) of the conditions from Lemma~\ref{proposition: nondegenerate for linear forms}.
\end{corollary}


\begin{definition}
  A bilinear form $(-,-) \colon A \times A \to k$ which is associative, symmetric and non-degenerate is a \emph{Frobenius bilinear form}.
  The corresponding linear form $\varepsilon \colon A \to k$ is a \emph{Frobenius linear form}.
\end{definition}


\begin{notation}
  By abuse of notation we will refer to both a Frobenius bilinear form and the corresponding Frobenius linear form as a \emph{Frobenius form}.
\end{notation}


\begin{definition}
  A \emph{Frobenius algebra} is a finite-dimesional $k$-algebra $A$ together with Frobenius form on $A$.
\end{definition}


\begin{remark}
  Let $A$ be a Frobenius algebra with Frobenius form $(-,-) \colon A \times A \to k$.
  Then the map
  \[
            \varphi
    \colon  A
    \to     A^*,
    \quad   a
    \mapsto (a,-)
  \]
  is injective because $(-,-)$ is non-degenerate,.
  It follows that $\varphi$ is an isomorphism because $A$ is finite-dimensional.
\end{remark}


\begin{example}
  \leavevmode
  \begin{enumerate}
    \item
      If $G$ is a finite group then the group algebra $k[G]$ can be endowed with the structure of a Frobenius algebra via the map $\varepsilon \colon k[G] \to k$ given on the basis $G$ of $k[G]$ by
      \[
          \varepsilon(g)
        = \begin{cases}
            1 & \text{if $g = e$} \,, \\
            0 & \text{otherwise}  \,,
          \end{cases}
      \]
      for every $g \in G$.
      In other words, $\varepsilon(\sum_{g \in G} a_g g) = a_e$ is the coefficient of the identity $e \in G$.
      
      For all $a, b \in kG$ with $a = \sum_{g \in G} \lambda_g g$ and $b = \sum_{g \in G} \mu_g g$ we have that
      \[
          \varepsilon(ab)
        = \sum_{g \in G} \lambda_g \mu_{g^{-1}}
        = \sum_{h \in G} \mu_h \lambda_{h^{-1}}
        = \varepsilon(ba)
      \]
      which shows that $\varepsilon$ is symmetric.
      If $a = \sum_{g \in G} a_g g \in k[G]$ with $a \neq 0$ then $a_g \neq 0$ for some $g \in G$ and it follows that
      \[
              \varepsilon(a g^{-1})
        =     \varepsilon\left( \sum_{h \in G} a_h h g^{-1} \right)
        =     \varepsilon\left( \sum_{h' \in G} a_{h' g} h' \right)
        =     a_g
        \neq  0 \,.
      \]
      Together this shows that $\varepsilon$ does indeed define a Frobenius form on $k[G]$.
      
      That the bilinear form $(-,-) \colon k[G] \times k[G] \to k$ corresponding to the linear form $\varepsilon$ is non-degenerate can also be seen by noticing that the corresponding linear map $k[G] \to k[G]^*$, $g \mapsto (g,-)$ maps every $g \in G$ to $(g^{-1})^*$, and therefore maps the basis $G$ of $k[G]$ bijectively onto its dual basis of $k[G]^*$.
    \item
      Let $k$ be a field and $n \geq 0$.
      Then $\Mat_n(k)$ can be endowed with the structure of a Frobenius algebra via the trace $\tr \colon \Mat_n(k) \to k$:
      
      We already know that $\tr(AB) = \tr(BA)$ for all $A, B \in \Mat_n(k)$.
      To show that the bilinear form $(-,-) \colon \Mat_n(k) \times \Mat_n(k)$ corresponding to $\varepsilon$ is non-degenerate we use the standard basis $E_{ij}$, $i,j = 1, \dotsc, n$ of $\Mat_n(k)$.
      We have that
      \[
          \tr( E_{ij} E_{pq} )
        = \tr( \delta_{jp} E_{iq} )
        = \delta_{jp} \tr(E_{iq})
        = \delta_{jp} \delta_{iq} \,.
      \]
      For all $i,j,p,q = 1, \dotsc, n$.
      If $A \in \Mat_n(k)$ is nonzero then for $A = \sum_{i,j=1}^n A_{ij} E_{ij}$ there exists some $i,j$ with $A_{ij} \neq 0$ and it follows that
      \[
              \tr( A E_{ji} )
        =     \sum_{p,q=1}^n A_{pq} \tr( E_{pq} E_{ji} )
        =     A_{ij}
        \neq  0
      \]
      Altogether this shows that $\tr$ is a Frobenius form on $\Mat_n(k)$.
  \end{enumerate}
\end{example}


\begin{proposition}
  Let $A$ be a Frobenius algebra with Frobenius form $(-,-)$.
  Then the map
  \[
            \psi
    \colon  Z(A)
    \to     (A/[A,A])^*,
    \quad   a
    \mapsto (a,-)
  \]
  is a well-defined isomorphism of $k$-vector spaces.
\end{proposition}


\begin{proof}
  The map
  \[
            \varphi
    \colon  A
    \to     A^*,
    \quad   a
    \mapsto (a, -)
  \]
  is an isomorphism of $k$-vector spaces because $A$ is finite-dimensional and $(-,-)$ is non-degenerate.
  We prove the proposition by showing that for every $z \in A$ we have that
  \[
          \restrict*{\varphi(z)}{[A,A]} = 0
    \iff  z \in \ringcenter(A) \,.
  \]
  For all $a, b \in A$ we have that
  \[
      (z,ba)
    = (1,zba)
    = (zba,1)
    = (zb,a)
    = (a,zb)
    = (az,b)
  \]
  and therefore
  \begin{align*}
        \varphi(z)([a,b])
    &=  (z,[a,b])
     =  (z,ab-ba)
     =  (z,ab) - (z,ba) \\
    &=  (za,b) - (az,b)
     =  (za-az,b)
     =  ([z,a],b)
  \end{align*}
  By using that $(-,-)$ is non-degenerate we find that
  \begin{align*}
          \restrict*{\varphi(z)}{[A,A]} = 0
    &\iff \forall a,b \in A: \varphi(z)([a,b]) = 0 \\
    &\iff \forall a,b \in A: ([z,a],b) = 0  \\
    &\iff \forall a \in A:   [z,a]  \\
    &\iff z \in \ringcenter(A) \,.
  \end{align*}
  This finishes the proof.
\end{proof}


% TODO: Add examples.




